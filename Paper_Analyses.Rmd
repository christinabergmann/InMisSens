---
title             : "The development of infants' responses to mispronunciations - A Meta-Analysis"
shorttitle        : "Mispronunciation Meta-Analysis"

author: 
  - name          : "Katie Von Holzen"
    affiliation   : "1,2"
    corresponding : yes    # Define only one corresponding author
    address       : "0221A LeFrak Hall, University of Maryland, College Park, MD 20742"
    email         : "katie.m.vonholzen@gmail.com"
  - name          : "Christina Bergmann"
    affiliation   : "3,4"

affiliation:
  - id            : "1"
    institution   : "Language Development Laboratory, University of Maryland, USA"
  - id            : "2"
    institution   : "Laboratoire Psychologie de la Perception, Université Paris Descartes"
  - id            : "3"
    institution   : "Max Planck Institute for Psycholinguistics, Nijmegen, the Netherlands"
  - id            : "4"
    institution   : "LSCP, Departement d'Etudes Cognitives, ENS, EHESS, CNRS, PSL Research University"

abstract: |
  One or two sentences providing a **basic introduction** to the field,  comprehensible to a scientist in any discipline.
  
  Two to three sentences of **more detailed background**, comprehensible  to scientists in related disciplines.
  
  One sentence clearly stating the **general problem** being addressed by  this particular study.
  
  One sentence summarizing the main result (with the words "**here we show**" or their equivalent).
  
  Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the  main result adds to previous knowledge.
  
  One or two sentences to put the results into a more **general context**.
  
  Two or three sentences to provide a **broader perspective**, readily comprehensible to a scientist in any discipline.
  
keywords          : "keywords"
wordcount         : "X"



floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no
citeproc          : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r Setup, echo = FALSE, warning=FALSE, warning = FALSE, error = FALSE, message = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, tidy = TRUE, message = FALSE, error = FALSE)

# wordcount()
# doesn't work...
# https://github.com/benmarwick/wordcountaddin


# bibliography      : ["MISP_MA_BIB.bib"]

# [KATIE] BIBLIOGRAPHY CURRENTLY REMOVED, AS IT IS CAUSING ERRORS WITH PAPAJA
# THIS IS PARTIALLY DUE TO THE WAY I CREATE IT USING MENDELEY. 
# TOO LAZY FOR THE MOMENT TO COMPLETELY OVERHAUL THIS

# BUT, OTHER PROBLEMS INCLUDE HAVING PAPAJA INSTALLED IN THE USER AND NOT SYSTEM LIBRARY
# https://github.com/crsh/papaja/issues/162
# devtools::with_libpaths(new = "/usr/lib/R/library/", install_github('crsh/papaja'))

# AND THE NEED TO SET citeproc: no
# https://github.com/crsh/papaja/issues/96

# STILL NEED TO FIGURE OUT WHAT ACTUAL PROBLEM IS, THIS IS CURRENTLY JUST A WORKAROUND


### Load libraries
library(papaja)
library(metafor)
library(meta)
library(pwr)
library(knitr)
library(ggplot2)
library(wesanderson)
library(grid)
library(gridExtra)
library(xtable)
library(schoRsch)
library(multcomp)
library(poibin)
library(tidyverse)

r2 <- function(x){ round(x, 3)}

psig <- function(x){
  ifelse(x < .001, "< .001",
         #ifelse(x < .001, "< .001",
                #ifelse(x < .01, "< .01",
                       ifelse(x > .001 & x < .05, paste("=", r2(x), sep = " "), paste("=", r2(x), sep = " ")))#))
}

# function for creating 1 line paired t.test results
t.xtable <- function(x) as.data.frame(xtable(
  t_out(toutput=x, n.equal = TRUE, welch.df.exact = TRUE, welch.n = NA,
        d.corr = TRUE, print = TRUE)
))


g_SE <- function(x) paste0(r2(x$estimate), " (SE = ", r2(x$se), ")")

CI_p <- function(x) paste0("(95% CI[", r2(x$ci.lb), ", ", r2(x$ci.ub), "], *p* ", psig(x$pval), ")")

full_estimate <- function(x) paste0(" = ", r2(x$estimate), ", SE = ", r2(x$se), ", 95% CI[",  r2(x$ci.lb), ", ", r2(x$ci.ub),"], *p*", psig(x$pval))


# moderator test
mod_test <- function(x) paste0("QM(", r2(rma_MPeffect$m), ") = ", r2(rma_MPeffect$QM), ", *p*", psig(rma_MPeffect$QMp))

```


```{r ReadIn}

#Get the effect size data
source("scripts/calculateES.R")

```

```{r Preprocess}

db_ET <- db_ET %>%
  mutate(age.C = (mean_age_1-mean(mean_age_1, na.rm=TRUE))/30.44) %>%
  filter(mean_age_months < 31)


db_ET$collapse <- paste(db_ET$study_ID, db_ET$expt_num, db_ET$same_infant, sep = "_")

# assign language families

db_ET$lang_family = ifelse(db_ET$native_lang=="American English" | db_ET$native_lang=="British English" | db_ET$native_lang=="Dutch" |
db_ET$native_lang=="Danish" | db_ET$native_lang=="Swedish" |
db_ET$native_lang=="English" | db_ET$native_lang=="German", "Germanic", ifelse(db_ET$native_lang == "French" | db_ET$native_lang == "Catalan" | db_ET$native_lang == "Spanish" | db_ET$native_lang == "Catalan-Spanish" | db_ET$native_lang == "Swiss French", 
                                "Romance", "Sino-Tibetian"))


#Split into correct and MP database

db_ET_correct <- db_ET[db_ET$is_correct=="1",]
db_ET_MP <- db_ET[db_ET$is_mp=="1",]

#collapse over nonindependent MP rows for a *general* MP effect


collapse_rows <- function(db){
  db$collapse <- paste(db$study_ID, db$expt_num, db$same_infant, sep = "_")
  
  for(independent in unique(db$collapse)){
    if(length(db[db$collapse==independent])>1){
      sub = db[db$collapse==independent, ]
      sub$d_calc <- median(sub$d_calc)
      sub$d_var_calc <- median(sub$d_var_calc)
      sub$g_calc <- median(sub$g_calc)
      sub$g_var_calc <- median(sub$g_var_calc)
      sub$corr_imputed <- median(sub$corr_imputed)
      db <- db[!(db$collapse==independent),]
      db <- rbind(db, sub[1,])
    }
  }
  return(db)
}


#db_ET_correct = collapse_rows(db_ET_correct)

#db_ET_MP = collapse_rows(db_ET_MP)

#remove outliers, for now we have none, though
db_ET_MP$nooutlier = ifelse(db_ET_MP$g_calc > mean(db_ET_MP$g_calc, na.rm = TRUE) + 3*sd(db_ET_MP$g_calc, na.rm = TRUE) 
                         | db_ET_MP$g_calc < mean(db_ET_MP$g_calc, na.rm = TRUE) - 3*sd(db_ET_MP$g_calc, na.rm = TRUE),FALSE, TRUE)
db_ET_MP = db_ET_MP[db_ET_MP$nooutlier,]

db_ET_correct$nooutlier = ifelse(db_ET_correct$g_calc > mean(db_ET_correct$g_calc, na.rm = TRUE) + 3*sd(db_ET_correct$g_calc, na.rm = TRUE) 
                         | db_ET_correct$g_calc < mean(db_ET_correct$g_calc, na.rm = TRUE) - 3*sd(db_ET_correct$g_calc, na.rm = TRUE),FALSE, TRUE)
db_ET_correct = db_ET_correct[db_ET_correct$nooutlier,]


# make sure that both correct and mispronounced conditions are considered in descriptives

db_ET_correct$condition <- 1
db_ET_MP$condition <- 0

dat <- bind_rows(db_ET_correct, db_ET_MP)

# need data set of unique short cite by expt_num
# in order to calculate total number of infants

# need data set of unique short cite by condition

sum_dat <- dat[!duplicated(dat[c("short_cite", "same_infant")]),]
time_wind_dat <- dat[!duplicated(dat[c("short_cite", "offset", "post_nam_dur")]),]
distract_dat <- dat[!duplicated(dat[c("short_cite", "object_pair")]),]
mix_co_mp <- dat[!duplicated(dat[c("short_cite", "word_correct_and_MP")]),]

```



```{r PlotAPATheme}
# Plotting defaults

#Themes and plot
apatheme=theme_bw()+
  theme(panel.grid.major=element_blank(),
    panel.grid.minor=element_blank(),
    panel.border=element_blank(),
    axis.line=element_line(),
    text=element_text(family='Times', size=25))

# Color Blind palette:
cbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

```

# Introduction

Acquiring a first language means that young learners are solving a host of tasks in a short amount of time. As infants develop into toddlers during their second and third years they learn new words in earnest while simultaneously refining their knowledge about the sounds that make up these words. Before children can correctly pronounce a word, they already show evidence of sensitivity to slight variations in the phonological form of that word. This mispronunciation sensitivity reflects the specificity with which infants represent the phonological information of familiar words and are sensitive to changes that might signal a change in word meaning. As infants continue to develop into expert language users, their language processing matures and becomes more efficient. In a mature phono-lexical system, word recognition must balance flexibility to slight variation (e.g., speaker identity, accented speech) while distinguishing between phonetic details that differentiate words in their native language (e.g. cat-hat). In this paper, we aggregate and analyze the almost 20 years of literature investigating mispronunciation sensitivity in infants in an attempt to uncover its characteristics and the trajectory of its development.

  At the turn of the millenia, infant language acquisition researchers had established that during their first years of life, infants are sensitive to changes in the phonetic detail of newly segmented words (Jusczyk & Aslin, 1995) and learned minimal pairs (Stager & Werker, 1997). Furthermore, when presented with familiar image pairs, children fixate on one image upon hearing its label (Fernald, Pinto, Swingley, Weinberg, & McRoberts, 1998). Swingley and Aslin (2000) were the first to tie these lines of research together and investigate mispronunciation sensitivity in infant familiar word recognition: Children aged 18 to 23 months learning American English were presented with pairs of images (e.g. baby, dog) and their eye movements to each image were coded offline. On "correct" trials, children heard the correct label for one of the images (e.g. baby). On "mispronounced" trials, children heard a mispronounced label of one of the images (e.g. vaby). Mean proportion of fixation to the target image (here: a baby) was calculated for both correct and mispronounced trials by dividing the target looking time by the sum of total looking time to both target and a distractor (proportion of target looking or PTL). Mean fixations in correct trials were significantly greater than in mispronounced trials, although looks to the target were significantly greater than chance in both types of trials. We refer to this pattern of a difference between looks to correct and mispronounced words as *mispronunciation sensitivity* and of looks to the target image above chance as *recognition*. Swingley and Aslin (2000) concluded that already before the second birthday, children represent words with sufficient detail to be sensitive to mispronunciations.  

  The study of Swingley and Aslin (2000) as well as subsequent studies examining mispronunciation sensitivity address two complementary concepts in early phonological development: *phonological constancy* and *phonological distinctiveness*. Phonological constancy is the ability to accept phonological variation across different instances of a word, as long as the variation does not compromise the overall identity of the word. For example, different speakers - particularly across genders and accents - produce the same word with notable acoustic variation, although the word remains the same. In contrast, phonological distinctiveness describes the ability to differentiate between different words that happen to be phonologically similar, such as bad/bed or cat/hat. To successfully recognize words, infants must therefore simultaneously use both phonological constancy and distinctiveness to determine where phonological variation is appropriate and where it changes a word's meaning.

  In the current study, we focus on infants' developing ability to correctly apply the principles of phonological distinctiveness and constancy by using a meta-analytic approach to investigate mispronunciation sensitivity. Considering that infants are sensitive to mispronunciations and that, in general, their processing matures with development, we examine the shape of mispronunciation sensitivity over the course of the second and third year. There are three distinct possibilities how mispronunciation sensitivity might change as infants become native speakers, which are all respectively predicted by theoretical accounts and supported by single studies. By aggregating all publicly available evidence using meta-analysis, we can examine developmental trends making use of data from a much larger and diverse sample of infants. Before we outline the meta-analytical approach and its advantages in detail, we first discuss the proposals this study seeks to disentangle and the data supporting each of the accounts.
  
  Young infants may begin cautiously in their approach to word recognition, rejecting any phonological variation in familiar words and only later learning to accept appropriate variability. According to the Perceptual Attunement account, this describes a shift away from specific native phonetic patterns to a more mature understanding of the abstract phonological structure of words (Best 1994, 1995). This shift is predicted to coincide with the vocabulary spurt around 18 months, and is therefore related to vocabulary growth. In this case, we would expect the size of mispronunciation sensitivity to be larger at younger ages and *decrease* as the child matures and learn more words, although children continue to detect mispronunciations.
Indeed, young infants are less likely than older infants to demonstrate recognition of familiar words (Best, Tyler, Gooding, Orlando, & Quann, 2009; Mulak, Best, & Tyler, 2013) or learn new words (Schmale, Hollich, & Seidl, 2011) from accented speakers.

  According to a different theoretical framework, young infants may instead begin with phonologically broad representations for familiar words and only refine their representations as language experience accumulates. PRIMIR (Processing Rich Information from Multidimensional Interactive Representations; Curtin & Werker, 2007; Werker & Curtin, 2005; Curtin, Byers-Heinlein, & Werker, 2011) describes the development of phonemic categories emerging as the number of word form-meaning linkages increases. Vocabulary growth, therefore, promotes more detailed phonological representations in familiar words. Following this account, we predict an *increase* in mispronunciation sensitivity as infants mature and add more words to their growing lexicon. 
  
  Finally, sensitivity to mispronunciation may not be modulated by development at all. Infants' overall language processing becomes more efficient, but their sensitivity to mispronunciations may not change. Across infancy and toddlerhood, mispronunciations would thus be detected and lead to less looks at a target than correct pronunciations, but the size of this effect would not change, nor be related to vocabulary size. This pattern is not predicted by any mainstream theory of language acquisition, but for completeness we mention it here.

  Research following the seminal study by Swingley and Aslin (2000) has extended mispronunciation sensitivity to infants as young as 12 months (Mani & Plunkett, 2010), indicating that from early stages of the developing lexicon onwards, infants can and do detect mispronunciations. Regarding the change in mispronunciation sensitivity over development, however, only a handful of studies have compared more than one age group on the same mispronunciation task (see Table X), making the current meta-analysis very informative. One study has found evidence for infants to become *less* sensitive to mispronunciations as children develop. Mani and Plunkett (2011) presented 18- and 24-month-olds with mispronunciations varying in the number of features changed (see below for a discussion of the role of features). 18-month-olds were sensitive to mispronunciations, regardless of the number of features changed. 24-month-olds, in contrast, fixated the target image equally for both correct and 1-feature mispronounced trials, although they were sensitive to larger mispronunciations. In other words, for 1-feature mispronunciations at least, sensitivity decreased from 18 to 24 months, providing support to the prediction that mispronunciation sensitivity may decrease with development.

  In contrast, other studies have found evidence for *greater* mispronunciation sensitivity as children develop. More precisely, the difference in target looking for correct and mispronounced trials is smaller in younger infants and grows as infants develop. Mani and Plunkett (2007) tested 15-, 18-, and 24-month-olds learning British English; although all three groups were sensitive to mispronunciations, 15-month-olds showed a less robust sensitivity. An increase in sensitivity to mispronunciations has also been found from 20 to 24 months (van der Feest & Fikkert, 2015) and 15 to 18 months (Altvater Mackensen et al., 2013) in Dutch infants, as well as German infants from 22 to 25 months (Altvater-Mackensen, 2010). Furthermore, van der Feest and Fikkert (2015) found that sensitivity to specific kinds of mispronunciations develop at different ages depending on language infants are learning. In other words, the native language constraints which *kinds* of mispronunciations infants are sensitive to first, and that as infants develop, they become sensitive to other mispronunciations. These studies award support to the prediction that mispronunciation sensitivity improves with development.

Finally, some studies have found no difference in mispronunciation sensitivity at different ages. Swingley and Aslin (2000) tested infants over a wide age range of 5 months (18 to 23 months).  They found that age correlated with target fixations for both correct and mispronounced labels, whereas the difference between the two (mispronunciation effect) did not. This suggests that as children develop, they are more likely to look at the target in the presence of a mispronounced label and that age is not related to mispronunciation sensitivity. A similar response pattern has been found for British English learning infants aged between 18 and 24 months (Bailey & Plunkett, 2002) as well as younger French-learning infants at 12 and 17 months (Zesiger, Lozeron, Levy, & Frauenfelder, 2012). These studies award support to the prediction that mispronunciation sensitivity does not change with development.

  Why would mispronunciation sensitivity change as infants develop, and would it increase or decrease? The main hypothesis is related to vocabulary growth. Both the Perceptual Attunement (Best, 1994; 1995) and PRIMIR (Curtin & Werker, 2007; Werker & Curtin, 2005; Curtin, Byers-Heinlein, & Werker, 2011) accounts situate a change in mispronunciation sensitivity occurring along with an increase in vocabulary size, particularly with the vocabulary spurt at about 18 months. Knowing more words helps infants shift their focus to the relevant phonetic dimensions needed for word recognition. On the one hand, a smaller lexicon does not require full specification to differentiate between words; as more phonologically similar words are learned, so does the need to have fully detailed representations for those words (Charles-Luce & Luce, 1995). On the other hand, a growing vocabulary is also related to more experience or familiarity with words, which may sharpen the detail of their representation (Barton, 1980).
  
  Yet, the majority of studies examining a potential association between mispronunciation sensitivity and vocabulary size have concluded that there is no relationship (Swingley & Aslin 2000; 2002; Bailey & Plunkett, 2002; Zesiger, Lozeron, Levy, & Frauenfelder, 2012; Swingley, 2009; Ballem & Plunkett, 2005; Mani & Plunkett, 2007; Mani, Coleman, & Plunkett, 2008). One notable exception comes from Mani and Plunkett (2010: keps and tups). Here, 12-month-old infants were divided into a low vocabulary and high vocabulary group based group median vocabulary size. High vocabulary infants showed greater sensitivity to vowel mispronunciations than low vocabulary infants, although this was not the case for consonant mispronunciations. Taken together, although receiving considerable support from theories of phono-lexical processing in language acquisition, there is very little evidence for a role of vocabulary size in mispronunciation sensitivity. In our current meta-analysis, we include the relationship between mispronunciation sensitivity and vocabulary size to further disentangle the disconnect between theory and experimental results. 

  Next to this core theoretically relevant investigation of the shape of development of infants' mispronunciation sensitivity, we take the opportunity of a systematic aggregation of data to address open questions regarding differences in experiment design and whether changes in procedure and stimuli tap into significantly different aspects of infants' ability to detect mispronunciations. 

  In designing their mispronunciation stimuli, Swingley and Aslin (2000) chose consonant mispronunciations that were likely to confuse adults (Miller & Nicely, 1955). Subsequent research has settled on systematically modulating phonemic features to achieve mispronunciations of familiar words. By utilizing mispronunciations consisting of phonemic changes, these experiments examine infants’ sensitivity to factors that change the identity of a word on a measurable level (i.e. 1-feature, 2-features, 3-features, etc.). The importance of controlling for the degree of phonological mismatch, as measured by number of features changed, is further highlighted by studies that find graded sensitivity to both consonant (White & Morgan, 2008) and vowel (Mani & Plunkett, 2011) feature changes.

  Although most research examining sensitivity to mispronunciations follows a similar design, there are some notable differences.  For example, Swingley and Aslin (2000) presented infants with pairs of familiar images, one serving as the labeled target and one as the unlabeled distractor. In contrast, White and Morgan (2008; see also Mani & Plunkett, 2011; Skoruppa et al., 2013; Swingley, 2016) presented infants with pairs of familiar (labeled target) and unfamiliar (unlabeled distractor) objects. By using an unfamiliar object as a distractor, the infant is presented with a viable option onto which the mispronounced label can be applied (Halberda, 2003; Markman, Wasow, & Hansen, 2003). Infants ages 24 and 30 months associate a novel label with an unfamiliar object, although only 30-month-olds retained this label-object pairing (Bion, Borovsky, and Fernald, 2013). In contrast, 18-month-olds did not learn to associate a novel label with an unfamiliar object, providing evidence that this ability is developing from 18 to 30 months. We may find that if mispronunciation sensitivity changes as children develop, that this change is modulated by whether the distractor used is familiar or unfamiliar. Although mispronunciation sensitivity in the presence of a familiar compared to unfamiliar distractor has not been directly compared, the baseline preference for familiar compared to novel stimuli is also thought to change as infants develop (Hunter & Ames, 1988).  Furthermore, young children have been found to look longer at objects for which they know the name, compared to objects of an unknown name (Schafer & Plukett, 1998). In other words, in absentia of a label, infants may be more or less likely to fixate on an unfamiliar object. To account for inherent preferences to the target or distractor image, mispronunciation experiments typically compare the increase in fixations to the target image from a silent baseline to post-labeling or present the same yoked pairs of target and distractor images in in both a correct and mispronounced labelling context. Considering this evidence, we may expect that in older, but not younger, children, the presence of an unfamiliar distractor may lead to greater mispronunciation sensitivity than in the presence of a familiar distractor.

  Furthermore, when presenting infants with a familiar distractor image, some studies control the phonological overlap between the labels for the target and distractor. For example, when examining sensitivity to a mispronunciation of the target word "dog", the vowel mispronunciation "dag" would be paired with a distractor image that shares onset overlap, such as "duck". This ensures that infants can not use the onset of the word to differentiate between the target and distractor images (Fernald, Swingley, & Pinto, 2001). Instead, infants must pay attention to the mispronounced phoneme in order to successfully detect the change. The influence of distractor overlap also depends on the position of the mispronunciation in the word, which can be at word onset, medial, or final positions. Models of spoken word processing place more or less importance on the position of a phoneme in a word.  The COHORT model (Marslen-Wilson & Zwitserlood, 1989) describes lexical access in one direction, with the importance of each phoneme decreasing as its position comes later in the word.  In contrast, the TRACE model (McClelland & Elman, 1986) describes lexical access as constantly updating and reevaluating the incoming speech input in the search for the correct lexical entry, and therefore can recover from word onset and to a lesser extent medial mispronunciations. 
  
  TRACE has also been used to model infants' sensitivity to mispronunciation location (Mayor & Plunkett, 2014), finding that as lexicon size increases, so does sensitivity to onset mispronunciations, whereas medial mispronunciations do not experience similar growth. In early language acquisition, infants typically know more consonant compared to vowel onset words. When tested on their recognition of familiar words, therefore, younger infants would show greater sensitivity to onset mispronunciations, which are frequently consonant mispronunciations. The prevalence of consonant onset words may contribute to the finding that consonants carry more weight in lexical processing (C-bias; see Nazzi, Poltrock, & Von Holzen, 2016 for a recent review). In mispronunciation sensitivity, this would translate to consonant mispronunciations impairing word recognition to a greater degree than vowel mispronunciations. Yet, the handful of studies directly comparing sensitivity to consonant and vowel mispronunciations mostly find symmetry as opposed to an asymmetry between consonants and vowels. English-learning 12-, 15-, 18-, and 24-month-olds (Mani & Plunkett, 2007; 2010 keps and tups) and Danish-learning 20-month-olds (Hojen et al., unpublished) demonstrate similar sensitivity to consonant and vowel mispronunciations. One study did find weak evidence for greater sensitivity to consonant compared to vowel mispronunciations (Swingley, 2016). The English-learning infants tested by Swingley were older than previous studies (mean age 28 months). In word learning, the C-bias has been found to develop later in English learning infants (Floccia, Nazzi, Delle Luche, Poltrock, & Goslin, 2014; Nazzi, Floccia, Moquet, & Butler, 2009). In the current meta-analysis, we attempt to synthesize studies examining sensitivity to consonant and vowel mispronunciations across different ages to determine whether infants generally exhibit more sensitivity to consonant compared to vowel mispronunciations in familiar word recognition as predicted by a learned account of C-bias emergence (Floccia et al., 2014; Keidel et al., 2007; Nazzi et al., 2016). We further examine the impact of language family on mispronunciation sensitivity to consonants and vowels, as C-bias emergence has been found to have a different developmental trajectory for Romance (French, Italian) compared to Germanic (British English, Danish) languages (Nazzi et al., 2016).
  
[KATIE] Christina had noted something to herself for this paragraph: Subset by language?

  Finally, mispronunciation sensitivity in infants has been examined in many different languages, such as English, Spanish, French, Dutch, German, Catalan, Danish, and Mandarin Chinese (see Summary_Table). Infants learning different languages have different ages of acquisition for words in their early lexicon, leaving direct comparisons between languages within the same study difficult and as a result rare. Yet, studies testing infants from different language backgrounds on similar sets of stimuli find similar sensitivity to mispronunciations (Ramon-Casas et al., 2009; Ramon-Casas & Bosch, 2010). Although we do not explicitly compare overall mispronunciation sensitivity by language (although see previous paragraph for rationale to test by language family), we assess evidence of mispronunciation sensitivity from many different languages using a meta-analytic approach.
  
Taken together, the studies we have reviewed begin to paint a picture of the development of mispronunciation sensitivity. Each study contributes one separate brushstroke and it is only by examining all of them together that we can achieve a better understanding. In our analysis, we examine the factors modulating the development of mispronunciation sensitivity, which are both of theoretical and practical importance. Meta-analyses can not only help us summarize the current state of research, but can also help us evaluate theories to drive future research and make hands-on recommendations for experiment planning. 


# Methods

The present meta-analysis was conducted with maximal transparency and reproducibility in mind. To this end, we provide all data and analysis scripts on the supplementary website (https://osf.io/rvbjs/) and open our meta-analysis up for updates (Tsuji, Bergmann, & Cristia, 2014). The most recent version is available via the website and the interactive platform MetaLab (metalab.stanford.edu; Bergmann et al., 2018). Since the present paper was written with embedded analysis scripts in R [@R], it is always possible to re-analyze an updated dataset. In addition, we follow the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines and make the corresponding information available as supplementary materials (Moher, Liberati, Tetzlaff, Altman & PRISMAGroup, 2009). Figure X plots our PRISMA flowchart.

![Figure X. PRISMA Flowchart.] (figures/PRISMA_MA_Mispronunciation.png)

## Study Selection

```{r SummaryTable}

dat_st <- dat

dat_st$object_pair <- ifelse(dat_st$object_pair == "familiar_familiar", "Familiar", "Unfamiliar")

Sum_table <- dat_st %>%
      group_by(short_cite) %>% 
      summarise(Ages_Tested_months = paste(unique(trunc(mean_age_1/30.34)), collapse=', '),
                Vocabulary = ifelse(all(is.na(r_comprehension)) & all(is.na(r_production)), "None",
                                ifelse(!all(is.na(r_comprehension)) & !all(is.na(r_production)), "Comprehension/Production",
                                       ifelse(!all(is.na(r_comprehension)) & all(is.na(r_production)), "Comprehension", "Production"))),
                Number_of_Features = paste(unique(n_feature), collapse=', '),
                Distractor_Familiarity = paste(unique(object_pair), collapse=', '),
                Distractor_Overlap = paste(unique(distractor_overlap), collapse=', '),
                Mispronunciation_Position = paste(unique(mispron_location), collapse=', '),
                Mispronunciation_type = paste(unique(type_feature), collapse=', '))

kable(Sum_table, col.names = c("Paper", "Age", "Vocabulary", "# Features", "Distractor", "Distractor name overlap", "MP Position", "MP Type"))

```

[KATIE] THIS TABLE IS DEFINITELY NOT FINISHED!
[CHRISTINA suggestions: N features should be a range and exclude 0; we could abbreviate Comperehension/Production to Comp./Prod., etcetc]
[KATIE] I'll think about how to implement that! Might end up having to adjust the table by hand, there is a lot of variation between studies.

We first generated a list of potentially relevant items to be included in our meta-analysis by creating an expert list. This process yielded 110 items. We then used the google scholar search engine to search for papers citing the original Swingley & Aslin (2000) publication. This search was conducted on 22 September, 2017 and yielded 288 results. We screened the 398 items, removing 99 duplicate items. We screened remaining 299 items for their title and abstract to determine whether it met the following inclusion criteria: (1) original data was reported; (2) the experiment examined familiar word recognition; (3) infants studied were under 36-months-of-age; (4) the dependent variable was derived from proportion of looks to a target image versus a distractor in a eye movement experiment; 5) the stimuli were auditory speech. The final sample (n = *`r length(unique(dat$short_cite))`*) consisted of `r with(dat, n_distinct(short_cite[publication_status == "paper"]))` journal articles, `r with(dat, n_distinct(short_cite[publication_status == "proceedings"]))` proceedings paper, `r with(dat, n_distinct(short_cite[publication_status == "dissertation"]))` thesis, and `r with(dat, n_distinct(short_cite[publication_status == "gray paper"]))` unpublished reports. We will refer to these items collectively as papers. Table 1 (Summary Table) provides an overview of all papers included in the present meta-analysis.


```{r DescriptivesPubtype}

pub_info <- dat %>%
  group_by(publication_status) %>%
  summarize(n_unique = n_distinct(short_cite), count = n())

#kable(pub_info, col.names = c("Publication Type", "# Items", "# Effect Sizes"))


```

## Data Entry

The `r length(unique(dat$short_cite))` papers we identified as relevant were then coded with as much detail as possible (Tsuji, Bergmann, & Cristia, 2014; Bergmann et al., 2018). For each experiment (note that a paper typically has multiple experiments), we entered variables describing the publication, population, experiment design and stimuli, and results. For the present analyses, we focus on the following characteristics:   
1 Condition: Were words mispronounced or not;  
2 Mean age reported per group of infants, in days;  
3 Vocabulary size, measured by a standardized questionnaire or list;    
4 Size of mispronunciation, measured in features changed;  
5 Distractor familiarity: familiar or unfamiliar;  
6 Phonological overlap between target and distractor: onset, onset/medial, rhyme, none, novel word;  
7 Position of mispronunciation: onset, medial, offset, or mixed;  
8 Type of mispronunciation: consonant, vowel, or both. 

We separated out conditions according to whether or not the target word was mispronounced to be able to investigate infants' looking to the target picture separated by whether or not words were mispronounced as well as their mispronunciation sensitivity, which is the difference between looks to the target in correct and mispronounced trials. When the same infants were further exposed to multiple mispronunciation conditions and the results were reported separately in the paper, we also entered each condition as a separate row  (e.g., consonant versus vowel mispronunciations; Mani & Plunkett, 2007).  The fact that the same infants contributed data to multiple rows (minimally those containing information on correct and mispronounced trials) leads to shared variance across effect sizes, which we account for in our analyses (see next section). We will call each row a record; in total there were `r nrow(dat)` records in our data.

## Data analysis

```{r DescriptivesComparison, echo = FALSE}
db_ET_correct$within_measure_descriptive <- ifelse(db_ET_correct$within_measure == "post",
 "post-naming phase compared with chance (=50%)",
ifelse(db_ET_correct$within_measure == "pre_post", "post-naming compared to pre-naming phase", "post-pre difference score compared with chance (=0)"))

comparison_info <- db_ET_correct %>%
  group_by(within_measure_descriptive) %>%
  summarize(n_unique = n_distinct(short_cite), count = n())

#kable(comparison_info, col.names = c("Type of comparison", "# Papers", "# Effect Size"))
#table(db_ET_MP$es_method)
```

```{r DescriptivesES}
#how did we calculate effect sizes?

es_info <- dat %>%
  group_by(es_method) %>%
  summarize(n_unique = n_distinct(short_cite), count = n())


corr_info <- dat %>%
  group_by(imputed_corr) %>%
  summarize(n_unique = n_distinct(short_cite), count = n())

```

Mispronunciation sensitivity studies typically examine infants' proportion of target looks (PTL) in comparison to a baseline measurement. PTL is calculated by dividing the percentage of looks to the target by the total percentage of looks to both the target and distractor images. Across papers the baseline comparison varied; we used the baseline reported by the authors of each paper. Most papers (*n* = `r with(db_ET_correct, n_distinct(short_cite[within_measure == "pre_post_naming_effect"]))`) subtracted the PTL score for a pre-naming phase from the PTL score for a post-naming phase. When interpreting this difference score, a positive value indicates that infants increased their looks to the target after hearing the naming label (correct or mispronounced). Other papers either compared post- and pre-naming PTL with one another (*n* = `r with(db_ET_correct, n_distinct(short_cite[within_measure == "pre_post"]))`) or compared post-naming PTL with a chance level of 50%, (*n* = `r with(db_ET_correct, n_distinct(short_cite[within_measure == "post"]))`). For all these comparisons, a positive difference score or a post-naming phase PTL score that is greater than the pre-naming phase PTL or chance indicate target looks that indicate object recognition after hearing the naming label. Consequently, positive effect sizes reflect more looks to the target picture after naming, and larger positive effect sizes indicate comparatively more relative increase in looks to the target. 

We report effect sizes for infants' looks to target pictures after hearing a correctly pronounced or a mispronounced label (object identification) as well as the difference between effect sizes for correct and mispronounced trials (i.e. mispronunciation sensitivity). The effect size we report in the present paper are based on comparison of means, standardized by their variance. The most well-known effect size from this group is Cohen's *d* [@cohen]. To correct for the small sample sizes common in infant research, however, we use as a dependent variable Hedges' *g* instead of Cohen's *d* (Hedges, 1981; Morris, 2000). 

We calculated Hedges' *g* using the raw means and standard deviations reported in the paper (*n* = `r with(es_info, n_distinct(n_unique[es_method == "group_means_one" | es_method == "group_means_two"]))`) or using reported t-values (*n* = `r with(es_info, n_distinct(n_unique[es_method == "t_one" | es_method == "t_two"]))`). Raw means and standard deviations were extracted from figures for `r with(dat, n_distinct(short_cite[ x_from_graph == "yes"]))` papers. In a within-participation design, when two means are compared (i.e. looking during pre- and post-naming) it is necessary to obtain correlations between the two measurements at the participant level to calculate effect sizes and effect size variance based on t-values. Upon request we were provided with correlation values for one paper (Altvater-Mackensen, 2010); we were able to compute correlations using means, standard deviations, and t-values for *n* = `r with(corr_info, n_unique[imputed_corr == "no"]) - 1` (following Csibra, et al. 2016, Appendix B; see also Rabagliati, Ferguson, & Lew-Williams, 2018). Correlations were imputed for the remaining papers (see Black & Bergmann, 2017, for the same procedure). We could compute a total of `r sum(dat$is_mp == 0)` effect sizes for correct pronunciations and `r sum(dat$is_mp == 1)` for mispronunciations.

To take into account the fact that the same infants contributed to multiple datapoints, we analyze our results in a multilevel approach using the R [@R] package metafor [@metafor]. This means we model as random effect that effect sizes from the same paper share are based on more similar studies than those across papers and that nested therein effects can stem from the same infants. 

## Publication Bias

[CHRISTINA: Do you think we have to revise this section? I think it's the same as in the proceedings paper.]
[KATIE: Are you concerned about the Publication Bias section in particular, or the Methods as a whole? In general, some of the Methods was written before the CogSci paper and in other places to flesh things out I rewrote what we had in the CogSci paper. Its definitely giving the same information and sometimes the wording is close, because there's not too many different ways to explain what a funnel plot is :)]

In the psychological sciences, there is a documented reluctance to publish null results. As a result, there is a potential for significant results to be valued over non-significant results (see Ferguson & Heene, 2012). To examine whether this is also the case in the mispronunciation sensitivity literature, which would bias the data analyzed in this meta-analysis, we conduct two tests. We first examine whether effect sizes are distributed as expected based on sampling error using the rank correlation test of funnel plot asymmetry with the R [@R] package metafor [@metafor]. Effect sizes with low-variance are expected to fall closer to the estimated mean, while effect sizes with high-variance should show an increased, evenly-distributed spread around the estimated mean. Second, we analyze all of the significant results in the dataset using a p-curve from the p-curve app (v4.0, p-curve.com; @pcurve). This tests for evidential value by examining whether the p-values have an expected distribution, regardless of whether the null hypothesis is true or not, as well as whether there is a larger proportion of p-values just below the typical alpha threshold of .05, which may indicate questionable research practices. Responses to correctly pronounced and mispronounced labels are predicted to show different patterns of looking behavior; as a result, we conduct these two analyses to assess publication bias separately for both conditions.

## Meta-analysis

The models reported are hierarchical random-effects models (infant groups nested within papers) of variance-weighted effect sizes with the R [@R] package metafor [@metafor]. To investigate how development impacts mispronunciation sensitivity, our core theoretical question, we introduce age (centered; continuous and measured in days but transformed into months for ease of reading by dividing by 30.44) as a moderator to our main model. For the subsequent investigations of experimental characteristics, we introduce each characteristic as a moderator (more detail below).

[CHRISTINA: Let's both reread the full paper once it is ready and check that this is properly motivated and whether we do need to list them all. For now I think the last sentence is fine, but I would tend to prefer a reminder for the forgetful reader.]
[KATIE: that's reasonable! We had just listed everything 7 paragraphs before, which doesn't seem like a lot of "space". Alternatively, this information could be listed in a table, and then just referred to.]

# Results

## Publication Bias

```{r FunnelPlotAsymm_correct}

rma_correct = rma.mv(g_calc, g_var_calc, data = db_ET_correct, random = ~ collapse | short_cite)
# Publication bias can become visible in funnel plot asymmetry. 
# Metafor comes with several options to check this, I chose ranktest and regtest
# correct object identification
rmac <- ranktest(rma_correct)
#rmac

```

```{r FunnelPlotAsymm_misp}

rma_MP = rma.mv(g_calc, g_var_calc, data = db_ET_MP, random = ~ collapse | short_cite)

# mispronounced object identification
rmam <- ranktest(rma_MP)
#rmam
```

Figure 1 shows the funnel plots for both correct pronunciations and mispronunciations (code adapted from Sakaluk, 2016). Funnel plot assymmetry was significant for both correct pronunciations (Kendall's $\tau$ = `r r2(rmac$tau)`, *p* `r psig(rmac$pval)`) and mispronunciations (Kendall's $\tau$ = `r r2(rmam$tau)`, *p* `r psig(rmam$pval)`). These results, quantifying the assymmetry in the funnel plots (Figure 1), indicate bias in the literature. This is particularly evident for correct pronunciations, where larger effect sizes have greater variance (bottom right corner) and there are a smaller number of more precise effect sizes (i.e. smaller variance) than expected (top left, outside the triangle).

The stronger publication bias for correct pronunciation might reflect the status of this condiction as a control. If infants were not looking to the target picture after hearing the correct label, the overall experiment design is called into questions. However, due to the small effect and sample sizes (which we will discuss in the following sections in more detail) one would expect the regular occurrence of null results even though as a population infants would reliably show the expected object identification effect.

We should also point out that funnel plot asymmetry can be caused by multiple factors beside publication bias. The funnel plot asymmetry may also reflect heterogeneity in the data, perhaps due to some studies investigating more subtle effects than other studies.  [CHRISTINA: I have to add some bits here.]

```{r FunnelPrep}
### Plots adapted from Sakaluk, 2016, see also Black & Bergmann, 2017
### https://sakaluk.wordpress.com/2016/02/16/7-make-it-pretty-plots-for-meta-analysis/

#Themes and plot
funnel_theme=theme_bw()+
  theme(#panel.grid.major=element_blank(),
    #panel.grid.minor=element_blank(),
    #panel.border=element_blank(),
    axis.line=element_line(),
    text=element_text(family='Times', size=22),
    legend.position='none')

```

```{r FunnelCorrect}

#Rename a bunch of things for ease
dat_co = db_ET_correct %>% 
  rename(cite = short_cite,
         yi = g_calc,
         vi = g_var_calc) %>%
  mutate(study_ref = paste(cite, expt_num, same_infant, sep=',')) %>% 
  dplyr::select(cite, expt_num, same_infant, mean_age_1, yi, vi) %>%
  arrange(desc(yi))

#Reorder bibliographic info based on value of g (yi), so effect sizes can be plotted in descending order


#Get standard errors from variances
dat_co$se = sqrt(dat_co$vi)

#Calculate 95% CI values
dat_co$lowerci = (-1.96*dat_co$se)+dat_co$yi
dat_co$upperci = (1.96*dat_co$se)+dat_co$yi


#Store the meta-analytic estimate and its standard error from whatever model you run
#summary(rma_correct)
estimate_co = coef(summary(rma_correct))$estimate
se_co = coef(summary(rma_correct))$se

#Store a vector of values that spans the range from 0
#to the max value of impression (standard error) in your dataset.
#Make the increment (the final value) small enough (I choose 0.001)
#to ensure your whole range of data is captured
se.seq_co=seq(0, max(dat_co$se), 0.001)

#Now, compute vectors of the lower-limit and upper limit values for
#the 95% CI region, using the range of SE that you generated in the previous step, 
#and the stored value of your meta-analytic estimate.
ll95_co = estimate_co-(1.96*se.seq_co)
ul95_co = estimate_co+(1.96*se.seq_co)

#You can do this for a 99% CI region too
ll99_co = estimate_co-(3.29*se.seq_co)
ul99_co = estimate_co+(3.29*se.seq_co)

#And finally, do the same thing except now calculating the confidence interval
#for your meta-analytic estimate based on the stored value of its standard error
meanll95_co = estimate_co-(1.96*se_co)
meanul95_co = estimate_co+(1.96*se_co)

#Now, smash all of those calculated values into one data frame (called 'dfCI').
#You might get a warning about '...row names were found from a short variable...'
#You can ignore it.
dfCI_co = data.frame(ll95_co, ul95_co, ll99_co,
                  ul99_co, se.seq_co, estimate_co, meanll95_co, meanul95_co)

#Now we can actually make the funnel plot.
#Using your original data-frame, map standard error to your x-axis (for now) and Zr to your y-axis
fp_co = ggplot(aes(x = se, y = yi), data = dat_co) +
  #Regression line for the FP asymmetry
  geom_smooth(aes(x = se, y = yi), method = "lm", colour = "darkgrey", alpha = .5, se = FALSE, data = dat_co) +
  #Add your data-points to the scatterplot
  geom_point(size = 2.5, colour="black") +
  #
  #Give the x- and y- axes informative labels
  xlab('Standard Error') + ylab('Hedge\'s g')+
  # give it a title
    ggtitle("Correct") +
    # make sure both plots have same scale
    # still ylim because we haven't flipped yet
    #coord_cartesian(ylim = c(0.5, 0))+
  #Now using the 'dfCI' data-frame we created, plot dotted lines corresponding
  #to the lower and upper limits of your 95% CI region
  #And dashed lines corresponding to your 99% CI region
  #Add lines corresponding to 0 and estimate
  geom_line(aes(x = se.seq_co, y = 0), linetype = 'solid', data = dfCI_co) +
  geom_line(aes(x = se.seq_co, y = estimate_co), linetype = 'dashed', data = dfCI_co) +
  geom_line(aes(x = se.seq_co, y = ll95_co), linetype = 'dotted', data = dfCI_co) +
  geom_line(aes(x = se.seq_co, y = ul95_co), linetype = 'dotted', data = dfCI_co) +
  #  geom_line(aes(x = se.seq, y = ll99), linetype = 'dashed', data = dfCI) +
  #  geom_line(aes(x = se.seq, y = ul99), linetype = 'dashed', data = dfCI) +
  #Now plot dotted lines corresponding to the 95% CI of your meta-analytic estimate
  #geom_segment(aes(x = min(se.seq), y = meanll95, xend = max(se.seq), yend = meanll95), linetype='dotted', data=dfCI) +
  #geom_segment(aes(x = min(se.seq), y = meanul95, xend = max(se.seq), yend = meanul95), linetype='dotted', data=dfCI) +
  #Reverse the x-axis ordering (se) so that the tip of the funnel will appear
  #at the top of the figure once we swap the x- and y-axes...
  scale_x_reverse()+
  #Specify the range and interval for the tick-marks of the y-axis (Zr);
  #Choose values that work for you based on your data
  #scale_y_continuous(breaks=seq(-.45,0.8,0.25))+
  #And now we flip the axes so that SE is on y- and Zr is on x-
  coord_flip()+
  #Finally, apply my APA-format theme (see code at end of post).
  #You could, alternatively, specify theme_bw() instead.
  funnel_theme

#Call the pretty funnel plot
#fp_co
#ggsave("figures/FunnelPlot_correct.pdf")

```

```{r FunnelMisp}

  #Rename a bunch of things for ease
dat_mp = db_ET_MP %>%
    rename(cite = short_cite,
           yi = g_calc,
           vi = g_var_calc) %>%
    dplyr::select(cite, expt_num, same_infant, mean_age_1, yi, vi) %>% 
    mutate(study_ref = paste(cite, expt_num, same_infant, sep=',')) %>% 
    arrange(desc(yi))
  
  #Reorder bibliographic info based on value of g (yi), so effect sizes can be plotted in descending order
  

  #Get standard errors from variances
  dat_mp$se = sqrt(dat_mp$vi)
  
  #Calculate 95% CI values
  dat_mp$lowerci = (-1.96*dat_mp$se)+dat_mp$yi
  dat_mp$upperci = (1.96*dat_mp$se)+dat_mp$yi
  
  
  #Store the meta-analytic estimate and its standard error from whatever model you run (substitute your own values)
  #summary(rma_MP)
  estimate_mp = coef(summary(rma_MP))$estimate
  se_mp = coef(summary(rma_MP))$se
  
  #Store a vector of values that spans the range from 0
  #to the max value of impression (standard error) in your dataset.
  #Make the increment (the final value) small enough (I choose 0.001)
  #to ensure your whole range of data is captured
  se.seq_mp=seq(0, max(dat_mp$se), 0.001)
  
  #Now, compute vectors of the lower-limit and upper limit values for
  #the 95% CI region, using the range of SE that you generated in the previous step, 
  #and the stored value of your meta-analytic estimate.
  ll95_mp = estimate_mp-(1.96*se.seq_mp)
  ul95_mp = estimate_mp+(1.96*se.seq_mp)
  
  #You can do this for a 99% CI region too
  ll99_mp = estimate_mp-(3.29*se.seq_mp)
  ul99_mp = estimate_mp+(3.29*se.seq_mp)
  
  #And finally, do the same thing except now calculating the confidence interval
  #for your meta-analytic estimate based on the stored value of its standard error
  meanll95_mp = estimate_mp-(1.96*se_mp)
  meanul95_mp = estimate_mp+(1.96*se_mp)
  
  #Now, smash all of those calculated values into one data frame (called 'dfCI').
  #You might get a warning about '...row names were found from a short variable...'
  #You can ignore it.
  dfCI_mp = data.frame(ll95_mp, ul95_mp, ll99_mp,
                       ul99_mp, se.seq_mp, estimate_mp, meanll95_mp, meanul95_mp)
  
  #Now we can actually make the funnel plot.
  #Using your original data-frame, map standard error to your x-axis (for now) and Zr to your y-axis
  fp_mp = ggplot(aes(x = se, y = yi), data = dat_mp) +
    #Regression line for the FP asymmetry
    geom_smooth(aes(x = se, y = yi), method = "lm", colour = "darkgrey", alpha = .5, se = FALSE, data = dat_mp) +
    #Add your data-points to the scatterplot
    geom_point(size = 2.5, colour="black") +
    #
  #Give the x- and y- axes informative labels
  xlab('Standard Error') + 
    # remove y label because it will be combined with the other funnel plot
    ylab('Hedge\'s g')+
    # give it a title
    ggtitle("Mispronunciation") +
    # make sure both plots have same scale
    # still xlim because we haven't flipped yet
    #coord_cartesian(xlim = c(0.5, 1))+
    #Now using the 'dfCI' data-frame we created, plot dotted lines corresponding
    #to the lower and upper limits of your 95% CI region
    #And dashed lines corresponding to your 99% CI region
    #Add lines corresponding to 0 and estimate
    geom_line(aes(x = se.seq_mp, y = 0), linetype = 'solid', data = dfCI_mp) +
    geom_line(aes(x = se.seq_mp, y = estimate_mp), linetype = 'dashed', data = dfCI_mp) +
    geom_line(aes(x = se.seq_mp, y = ll95_mp), linetype = 'dotted', data = dfCI_mp) +
    geom_line(aes(x = se.seq_mp, y = ul95_mp), linetype = 'dotted', data = dfCI_mp) +
    #  geom_line(aes(x = se.seq, y = ll99), linetype = 'dashed', data = dfCI) +
    #  geom_line(aes(x = se.seq, y = ul99), linetype = 'dashed', data = dfCI) +
    #Now plot dotted lines corresponding to the 95% CI of your meta-analytic estimate
    #geom_segment(aes(x = min(se.seq), y = meanll95, xend = max(se.seq), yend = meanll95), linetype='dotted', data=dfCI) +
    #geom_segment(aes(x = min(se.seq), y = meanul95, xend = max(se.seq), yend = meanul95), linetype='dotted', data=dfCI) +
    #Reverse the x-axis ordering (se) so that the tip of the funnel will appear
    #at the top of the figure once we swap the x- and y-axes...
    scale_x_reverse()+
    #Specify the range and interval for the tick-marks of the y-axis (Zr);
    #Choose values that work for you based on your data
    #scale_y_mpntinuous(breaks=seq(-.45,0.8,0.25))+
    #And now we flip the axes so that SE is on y- and Zr is on x-
    coord_flip()+
    #Finally, apply my APA-format theme (see previous).
    #You could, alternatively, specify theme_bw() instead.
    funnel_theme +
    theme(axis.title.y = element_blank())
  
  #Call the pretty funnel plot
  #fp_mp
#  ggsave("figures/FunnelPlot_misp.pdf")

```

## Figure 1

```{r FunnelCombo, echo = FALSE}


  jpeg(filename = "figures/Figure_1_Funnel_Plots_Object_Identification.jpg", 
       width = 600, height = 400, units = "px")
  
  p <-   grid.arrange(fp_co, fp_mp, nrow = 1)
                      #top = textGrob("Object Identification", gp=gpar(fontsize=25)))
                      #top = "Figure 1. Funnel Plots")
  dev.off()

    grid.draw(p)
  
```


```{r PcurveExport, echo = FALSE}

textfile_co = "p_curve_app/p_curve_co.txt"

# make sure the file is made new with our loop
if (file.exists(textfile_co)) {file.remove(textfile_co)}

for(line in 1:length(db_ET_correct$n_1)){
  if(!is.na(db_ET_correct[line,]$t)){
    newline = paste("t(", db_ET_correct[line,]$n_1-1, ")=",db_ET_correct[line,]$t, sep = "")
    write(newline, file = textfile_co, append = TRUE)
    #cat("\n")
    #write(newline, file = textfile, append = TRUE)    
  }
}

textfile_mp = "p_curve_app/p_curve_mp.txt"

# make sure the file is made new with our loop
if (file.exists(textfile_mp)) {file.remove(textfile_mp)}

for(line in 1:length(db_ET_MP$n_1)){
  if(!is.na(db_ET_MP[line,]$t)){
    newline = paste("t(", db_ET_MP[line,]$n_1-1, ")=",db_ET_MP[line,]$t, sep = "")
    write(newline, file = textfile_mp, append = TRUE)
    #cat("\n")
    #write(newline, file = textfile, append = TRUE)    
  }
}

```

```{r ReadIn_pcurve_app,  echo = FALSE, error = FALSE}


#Get the effect size data
source("scripts/p_curve_app_code.R")

# this gives the number of significant results
# the Z value
# and the significance
pcd_correct <- pcurve_app("p_curve_co.txt", "p_curve_app")
```


```{r ReadIn_pcurve_app_2,  echo = FALSE, error = FALSE}
pcd_misp <- pcurve_app("p_curve_mp.txt", "p_curve_app")

```

We next examined the p-curves for significant values from the correctly pronounced and mispronounced conditions. The p-curve based on `r pcd_correct$ksig` statistically significant values for correct pronunciations indicates that the data contain evidential value (Z = `r r2(pcd_correct$Zppr)`, *p* `r psig(pcd_correct$p.Zppr)`) and there is no evidence of a large proportion of p-values just below the typical alpha threshold of .05. The p-curve based on `r pcd_misp$ksig` statistically significant values for mispronunciations indicates that the data contain evidential value (Z = `r r2(pcd_misp$Zppr)`, *p* `r psig(pcd_misp$p.Zppr)`) and there is no evidence of a large proportion of p-values just below the typical alpha threshold of .05.

Taken together, the results suggest a tendency in the literature towards publication bias. As a result, our meta-analysis may systematically overestimate effect sizes and we therefore interpret all estimates with caution. Yet, the p-curve analysis suggests that overall, the literature contains evidential value, reflecting a "real" effect. We therefore continue our meta-analysis.

## Meta-analysis

### Object Identification for Correct and Mispronounced Words

```{r MAcorrect}

rma_correct = rma.mv(g_calc, g_var_calc, data = db_ET_correct, random = ~ collapse | short_cite)

#summary(rma_correct)
#kable(round(coef(summary(rma_correct)), 2))

sum_eff <- coef(summary(rma_correct))[1,]

```

We first calculated the meta-analytic effect for object identification, i.e. looks to the target image in response to correctly pronounced words. The variance-weighted meta-analytic effect size Hedges' *g* was `r g_SE(sum_eff)` which was significantly different from zero `r CI_p(sum_eff)`. This is a rather large effect size (according to the criteria set by Cohen, 1988; see also Bergmann, et al., 2018; for comparative meta-analytic effect sizes in language acquisition research). That the effect size is significantly above zero suggests that when presented with the correctly pronounced label, infants fixated the corresponding object. Our analysis of funnel plot asymmetry, however, found evidence for publication bias, which might lead to an overestimated effect sizes as smaller, non-significant results might not be published. Although the effect size Hedges' *g* may be overestimated for object identification in response to correctly pronounced words, the p-curve results and a CI lower bound of `r r2(sum_eff$ci.lb)` suggests that this result is robust even when correcting for publication bias. In other words, we are confident that the true population mean lies above zero for object recognition of correctly pronounced words.

[CHRISTINA: Can you explain what the CI lower bound means here? I don't follow.]
[KATIE: What do you think about this (last sentence)? The CI lower bound stuff here actually comes from something you wrote, so tell me whether its correct.]

```{r MAMP}

rma_MP = rma.mv(g_calc, g_var_calc, data = db_ET_MP, random = ~ collapse | short_cite)

#summary(rma_MP)

sum_eff <- coef(summary(rma_MP))[1,]

```

We then calculated the meta-analytic effect for object identification in response to mispronounced words. In this case, the variance-weighted meta-analytic effect size Hedges' *g* was `r g_SE(sum_eff)` which was also significantly different from zero `r CI_p(sum_eff)`. This is considered a small effect size (Cohen, 1988), but significantly above zero, which suggests that even when presented with a mispronounced label, infants fixated the correct object. In other words, infants are able to resolve mispronunciations, a key skill in language processing We again note the publication bias (which was smaller in this condition), and the possibility that the effect size Hedges' *g* may be overestimated. But, as the p-curve indicated evidential value, we are confident in the overall patterns, namely that infants fixate the target even after hearing a mispronounced label.

Heterogeneity was significant for both correctly pronounced (Q(103) = `r r2(rma_correct$QE)`, *p* `r psig(rma_correct$QEp)`) and mispronounced words, (Q(146) = `r r2(rma_MP$QE)`, *p* `r psig(rma_MP$QEp)`). This indicated that the sample contains unexplained variance leading to significant difference across our studies beyond what is to be expected based on random sampling error. We therefore continue with our moderator analysis. 

### Mispronunciation Sensitivity Meta-analytic Effect

```{r MPEffect}

rma_MPeffect <- rma.mv(g_calc, g_var_calc, mods = ~condition, data = dat, random = ~ collapse | short_cite)
  
#summary(rma_MPeffect)  

#rma_MPeffect_1 <- rma.mv(g_calc, g_var_calc, mods = ~condition-1, data = dat, random = ~ collapse | short_cite)
  
#summary(rma_MPeffect_1)  

sum_eff <- coef(summary(rma_MPeffect))[2,]

```

The above two analyses considered the data from mispronounced and correctly pronounced words separately. To evaluate mispronunciation sensitivity, we  compared the effect size Hedges' *g* for correct pronunciations with mispronunciations directly, merging the two datasets. The moderator test was significant, `r mod_test(rma_MPeffect)`.  Hedges' *g* for mispronunciation sensitivity was `r g_SE(sum_eff)`, which indicated that the responses across conditions were significantly different `r CI_p(sum_eff)`. This confirms that although infants fixate the correct object for both correct pronunciations and mispronunciations, the observed fixations to target (as measured by the effect sizes) were significantly greater for correct pronunciations. In other words, we observe a significant difference between the two conditions and can now quantify the modulation of fixation behavior in terms of standardized effect sizes.

### Object Recognition and Mispronunciation Sensitivity Modulated by Age

```{r MAcorrect_age}

rma_correct_age = rma.mv(g_calc, g_var_calc, mods = ~age.C, data = db_ET_correct, random = ~ collapse | short_cite)

#summary(rma_correct_age)
#kable(round(coef(summary(rma_correct_age)), 2))
#aov.type <- anova(rma_correct_age)

Csum_eff <- coef(summary(rma_correct_age))[2,]

```


```{r MAMP_age}

rma_MP_age = rma.mv(g_calc, g_var_calc, mods = ~age.C, data = db_ET_MP, random = ~ collapse | short_cite)

#summary(rma_MP_age)
#aov.type <- anova(rma_MP_age)

Msum_eff <- coef(summary(rma_MP_age))[2,]

```

To evaluate the different predictions we laid out in the introduction for how mispronunciation sensitivity will change as infants develop, we next added the moderator age (centered, in days). In the first analyses, we investigate the impact of age separately on conditions where words were either pronounced correctly or not. Age did not significantly modulate object identification in response to correctly pronounced `r mod_test(rma_correct_age)` or mispronounce words `r mod_test(rma_MP_age)`. The lack of a significant modulation together with the small estimates indicates that there was no relationship between age and target looks in response to a correctly pronounced or mispronounced label. This relationship is plotted in Figure 2.

```{r MPEffect_age}

rma_MPeffect_age <- rma.mv(g_calc, g_var_calc, mods = ~age.C*condition, data = dat, random = ~ collapse | short_cite)
  
# summary(rma_MPeffect_age)  
# 
# aov.type <- anova(rma_MPeffect_age)

sum_eff <- coef(summary(rma_MPeffect_age))[4,]

```

We then examined the interaction between age and mispronunciation sensitivity (correct vs. mispronounced words) in our whole dataset. The moderator test was significant `r mod_test(rma_MPeffect_age)`. This result is in line with the general observation that as infants mature they become better at language processing. The interaction between age and mispronunciation sensitivity, however, was not significant $\beta$`r full_estimate(sum_eff)`. The small estimate size, as well as inspection of Figure 2 suggests that as infants age, their mispronunciation sensitivity remains the same.

## Figure 2

```{r PlotMPEffect, echo = FALSE}

dat$condition_label = ifelse(dat$condition==1, "Correct", "Mispronunciation")

p <- ggplot(dat, aes(mean_age_1/30.44, g_calc, color = condition_label)) + 
  geom_point(aes(size = weights_g),show.legend=FALSE, alpha = .5) + 
  geom_line(y= 0, linetype="dotted") + 
  geom_smooth(method = "lm", formula = y ~ log(x), aes(weight=weights_g)) +
  scale_colour_manual(values=cbPalette)+
  apatheme +
  theme(legend.title = element_blank(),
        legend.position = "bottom",
        text = element_text(size = 40)) + 
  xlab("Age in months") + 
  ylab("Hedges' g")
  
p

# min(dat$mean_age_1/30.44)
# max(dat$mean_age_1/30.44)

#ggsave("figures/AgeEffect_log.jpg", p,height= 7,width= 6)



  jpeg(filename = "figures/Figure_2_AgeEffect.jpg", 
       width = 700, height = 400, units = "px")

  p
  
  dev.off()
  


```

### Vocabulary Size: Correlation Between Mispronunciation Sensitivity and Vocabulary

```{r VocabularyData, echo = FALSE}
vocab_info <- db_ET_correct %>%
  mutate(has_vocab = ifelse(!is.na(r_comprehension), "comprehension", 
                            ifelse(!is.na(r_production), "production", "none"))) %>%
  group_by(has_vocab) %>%
  summarize(count = n(),
            papers = n_distinct(short_cite))
  
#kable(vocab_info)

vocab_info2 <- db_ET_correct %>%
  mutate(has_vocab = ifelse(!is.na(r_comprehension) | !is.na(r_production), "vocab", 
                            "none")) %>%
  group_by(has_vocab) %>%
  summarize(count = n(),
            papers = n_distinct(short_cite))

vi1 <- as.data.frame(vocab_info)
vi2 <- as.data.frame(vocab_info2)

```

Of the `r n_distinct(dat$short_cite)` papers included in the meta-analysis, `r with(vi2, papers[has_vocab == "vocab"])` (comprehension = `r with(vi1, papers[has_vocab == "comprehension"])` papers; production = `r with(vi1, papers[has_vocab == "production"])`) analyzed the relationship between vocabulary scores and mispronunciation sensitivity, specifically object recognition for correct pronunciations and mispronunciations. There is reason to believe that production data are different from comprehension data (the former being easier to estimate for parents in the typical questionnaire-based assessment), so we analyze this data separately.

[CHRISTINA] SO WE DON'T WANT TO INTERPRET THE FIXED EFFECTS MODEL AT ALL, IT IS NOT SUITABLE BECAUSE THERE IS VARIANCE BETWEEN EVERY RECORD (LANGUAGE ETC).
I WOULD INTERPRET THE OVERALL CORRELATION AND THE CI, NOT THE P-VALUE (IN GENERAL). I ALSO WONDER WHETHER WE SHOULD MOVE THE SUBSET ANALYSES TO THE SUPPLEMENTARY MATERIALS AND JUST SAY OVERALL WE SEE NO RELATIONSHIPS AND CORRELATION COEFFICIENTS CONSISTENYL BELOW .1
WE THEREFORE MUST CONCLUDE THAT WITHIN NARROW AGE GROUPS VOCABULARY DOES NOT INFLUENCE ANYTHING WE LOOK AT. WE CANNOT DO THIS ANALYSIS FPOR MP SENSITIVITY BECAUSE WE DON'T HAVE THE NECESSARY RAW DATA.
[KATIE: Ah, so because for each paper the correlation and CI values straddle 0, this indicates that there really isn't much evidence for a relationship? I've tried to write this out below, let me know what you think. Over the summer, I had also played around with looking at how collection of vocabulary data has dropped off over the years, even though more mispronunciation studies have been published. That might be something interesting to add. If we truly think that this is what is driving the development of mispronunciation sensitivity, then why are people not collecting this data?]
(BUT I WONDER WHETHER WECOULD ENCODE THE REPORTED INTERACTION TERMS AND THE CORRELATION AND THEN DO SOMETHING WITH THAT?)
[KATIE: I'm not really sure what you mean by this :(]

```{r ComprehensionMeta_correct}
#we're relying on the library meta function metacor
compr  <- subset(db_ET_correct, !is.na(db_ET_correct$r_comprehension) & r_comprehension > -1)

CC <- metacor(cor=r_comprehension, n=n_1, studlab = short_cite, data = compr, sm = "COR")

# https://rdrr.io/cran/meta/man/forest.html
#forest(CC)

```

```{r ProductionMeta_correct}
#we're relying on the library meta function metacor
prodr  <- subset(db_ET_correct, !is.na(db_ET_correct$r_production) & r_production < 1)

CP <- metacor(cor=r_production, n=n_1, studlab = short_cite, data = prodr, sm = "COR")

```

[Katie: below, I'm using coweeta.uga.edu/publications/10436.pdf, page 80 as a model for writing up these results. I haven't the funniest clue what I'm doing! :p]

We first considered the relationship between vocabulary and object recognition for correct pronunciations. Higher comprehension scores were associated with greater object recognition in response to correct pronunciations for 9 of 12 experimental conditions, with correlation values ranging from -0.17 to 0.48. The mean effect size XXX was 0.0897, but did not differ significantly from zero (95% CI[-0.0105; 0.1900] *p* = .0795). Higher production scores were also associated with greater object recognition in response to correct pronunciations for 9 of 16 experimental conditions, with correlation values ranging from -0.23 to 0.44. The mean effect size XXX was 0.0601, but did not differ significantly from zero (95% CI[-0.0331; 0.1533] *p* = .2061). For both comprehension and production scores, the small correlation effect sizes and large variances suggest a lack of relationship between vocabulary and object recognition for correct pronunciations.

```{r ComprehensionMeta_MP}
#we're relying on the library meta function metacor
compr  <- subset(db_ET_MP, !is.na(db_ET_MP$r_comprehension) & r_comprehension > -1)

MC <- metacor(cor=r_comprehension, n=n_1, studlab = short_cite, data = compr, sm = "COR")
```

```{r ProductionMeta_MP}
#we're relying on the library meta function metacor
prodr  <- subset(db_ET_MP, !is.na(db_ET_MP$r_production) & r_production < 1)

MP <- metacor(cor=r_production, n=n_1, studlab = short_cite, data = prodr, sm = "COR")
```

We next considered the relationship between vocabulary and object recognition for mispronunciations. Higher comprehension scores were associated with greater object recognition in response to correct pronunciations for 17 of 31 experimental conditions, with correlation values ranging from -0.35 to 0.57. The mean effect size XXX was 0.0377, but did not differ significantly from zero (95% CI[-0.0260; 0.1014] *p* = .2465). For production, however, lower production scores were associated with greater object recognition in response to mispronunciations for 16 of 31 experimental conditions, with correlation values ranging from -0.28 to 0.44. The mean effect size XXX was -0.0402, but did not differ significantly from zero (95% CI[-0.1043; 0.0238] *p* = .2181). For both comprehension and production scores, the small correlation effect sizes and large variances suggest a lack of relationship between vocabulary and object recognition for mispronunciations.

### Interim Discussion

The main goal of this paper was to assess mispronunciation sensitivity and its maturation with age. The results are clear: Although infants consider a mispronunciation as a better match with the target image than a distractor image, there was a consistent effect of mispronunciation sensitivity. This did not change with development. Of the 3 predictions and assumptions about the development of infants' sensitivity to mispronunciations discussed in the Introduction, the present results lend some support for the argument that mispronunciation sensitivity stays consistent as infants develop. This runs counter to existing theories of phono-lexical development, which predict either an increase (PRIMR ref) or decrease (Assim Model ref) in mispronunciation sensitivity. Furthermore, counter to the predictions for the PRIMR (PRIMR ref) and Assimilation(Assim ref) models, we found no relationship between vocabulary and target looking for correct pronunciations or mispronunciations. In sum, it seems that current theories of infants' phono-lexical development cannot fully capture our results and should be reconsidered with all the evidence in mind.

Alternatively, the lack of developmental change in mispronunciation sensitivity could be due to differences in the types of tasks given to infants of different ages. In the following section, we investigate the role that different moderators play in mispronunciation sensitivity. To investigate the possibility of systematic differences in the tasks across ages, we additionally include an exploratory analysis of whether different moderators and experimental design features were included at different ages.

## Moderator Analyses

[cHRISTINA] I WOULD FOLLOW THE OUTLINE IN THE PREVIOUS PARAGRAPH HERE OR FLIP THE PARAGRAPH AROUND:
1. ARE DIFFERENT MODERATORS USED AT DIFFERENT AGES? 
TEST: sIMPLE CHI-SQUARED OF AGE GROUP VERSUS MODERATOR ASSIGNMENT (AGE GROUP DETERMINED BY LOOKING AT THE YOUNGEST AGE FOR X?)
2. WHICH MODERATORS INFLUENCE MP SENSITIVITY
TEST SIMPLE MA WITH MODERATOR TESTS

OR 
"FOR EACH POSSIBLE MODERATOR WHICH COULD INFLIENCE MP SENSITIVITY, WE FIRST TEST THIS POSSIBILITY AND THEN EVALUATE WHETHER THERE IS A SYSTEMATIC DIFFERENCE OF MANIPULATING THESE MODERATORS AS INFANTS MATURE, I.E. WHETHER OLDER INFANTS ARE TESTED ON A MORE DIFFICULT TASK "
ALSO, AS FINAL FOLLOW-UP IT WOULD BE PERFECT TO JUST SUBSET ALL STUDIES WITH FAMILIAR DISTRACTORS, SAME NUMBER OF FEATURES, AND CHECK THAT OUR CONCLUSIONS HOLD UP REGARING MP SENSITIVITY

[KATIE: I prefer this second option, first looking at the moderators in general and then looking at whether there is this systematic difference with age. The latter is exploratory, so I feel like this information should not preceed our planned analyses.]

### Number of features changed

```{r NFeatures_demographics}

dat.f  <- subset(dat, n_feature == "0" | n_feature == "1" |
                n_feature == "2" | n_feature == "3")

nfeature_info <- dat.f %>%
  group_by(n_feature) %>%
  summarize(n_exp_conditions =  n())

```

To assess whether the number of features changed modulates mispronunciation sensitivity, we calculated the meta-analytic effect for object identification in response to words that were pronounced correctly and mispronounced using 1-, 2-, and 3-feature changes. We did not include data for which the number of features changed in a mispronunciation was not specified or the number of features changed was not consistent (e.g., one mispronunciation included a 2-feature change whereas another only a 1-feature change). This analysis was therefore based on a subset of the overall dataset, with `r with(nfeature_info, n_exp_conditions[n_feature == 0])` experimental conditions for correct pronunciations, `r with(nfeature_info, n_exp_conditions[n_feature == 1])` for 1-feature mispronunciations, `r with(nfeature_info, n_exp_conditions[n_feature == 2])` for 2-feature mispronunciations, and `r with(nfeature_info, n_exp_conditions[n_feature == 3])` for 3-feature mispronunciations. Each feature change (from 0 to 3; 0 representing correct pronunciations) was considered to have an equal impact on mispronunciation sensitivity, following the argument of graded sensitivity (White & Aslin, 2008; Mani & Plunkett 2011). 


```{r NFeatures}

dat.f  <- subset(dat, n_feature == "0" | n_feature == "1" |
                n_feature == "2" | n_feature == "3")

rma_NFeatures <- rma.mv(g_calc, g_var_calc, mods = ~as.numeric(n_feature), data = dat.f, random = ~collapse | short_cite)

 sum_eff <- coef(summary(rma_NFeatures))[2,]


```

To understand the relationship between number of features changed and mispronunciation sensitivity, we  evaluated the effect size Hedges' *g* with number of features changed as a moderator. The moderator test was significant, `r mod_test(rma_NFeatures)`.  Hedges' *g* for number of features changed was `r g_SE(sum_eff)`, which indicated that as the number of features changed increased, the effect size Hedges' *g* significantly decreased `r CI_p(sum_eff)`. We plot this relationship in Figure 3. This confirms previous findings of a graded sensitivity to the number of features changed for both consonant (White & Morgan, 2008) and vowel (Mani & Plunkett, 2011) mispronunciations as well as the importance of controlling for the degree of phonological mismatch in experimental design.

## Figure 3

```{r PlotFeatEffect, echo = FALSE}

dat_f <- subset(dat, n_feature == "0" | n_feature == "1" |
                n_feature == "2" | n_feature == "3")

dat_f$feat_cat <- ifelse(dat_f$n_feature == 1, "1-feature",
                         ifelse(dat_f$n_feature == 2, "2-feature",
                                ifelse(dat_f$n_feature == 3, "3-feature",
                                       ifelse(dat_f$n_feature == 0, "correct", "none"))))

dat_f <- subset(dat_f, feat_cat != "none")

dat_f$Features_changed <- factor(dat_f$feat_cat, levels = c("correct", "1-feature", "2-feature", "3-feature"))

p <- ggplot(dat_f, aes(Features_changed, g_calc, fill = Features_changed)) + 
  geom_violin() + 
  geom_jitter(height = 0, width = 0.1, alpha = 0.5)+
  #geom_smooth(method = "lm", formula = y ~ log(x), aes(weight=weights_g)) + 
  scale_fill_manual(values=cbPalette)+
  apatheme +
  theme(text = element_text(size=25),
        legend.title = element_blank(),
        legend.position = "none",
        axis.title.x = element_blank()) + 
  #xlab("Number of Features Changed") + 
  geom_hline(yintercept = 0, linetype="dotted") + 
  ylab("Effect size Hedges' g")

p

  jpeg(filename = "figures/Figure_3_Number_of_Features.jpg", 
       width = 500, height = 300, units = "px")

  p
  
  dev.off()
  
  #[CHRISTINA] WHAT DO YOU THINK ABOUT VIOLIN PLOTS?

```

```{r NFeatures_age}

dat.f  <- subset(dat, n_feature == "0" | n_feature == "1" |
                n_feature == "2" | n_feature == "3")

rma_NFeatures <- rma.mv(g_calc, g_var_calc, mods = ~as.numeric(n_feature)*age.C, data = dat.f, random = ~collapse | short_cite)

 sum_eff <- coef(summary(rma_NFeatures))[4,]

```

Although we did not have any specific predictions about the relationship between infant age and the impact of number of features changed on mispronunciation sensitivity, we included an exploratory analysis to examine this relationship. When age was also included as a moderator, the moderator test was significant, `r mod_test(rma_NFeatures)`, but the interaction between age and number of features changed was not significant, $\beta$`r full_estimate(sum_eff)`. The small effect size for the interaction between age and number of features changed suggests that the impact of number of features changed on mispronunciation sensitivity does not change with infant age.


```{r NFeatures_subset}

dat_f <- subset(dat, n_feature == "0" | n_feature == "1" |
                n_feature == "2" | n_feature == "3")

nfeature_ages <- dat.f %>%
  group_by(n_feature) %>%
  summarize(min_age = r2(min(mean_age_1, na.rm=TRUE)),
            max_age = r2(max(mean_age_1, na.rm=TRUE)),
            mean_age = r2(mean(mean_age_1, na.rm=TRUE)))

mf <- subset(dat_f, n_feature == "3")
min_age <- min(mf$mean_age_1)
max_age <- max(mf$mean_age_1)

dat_fage= dat_f%>%
  filter(mean_age_1>=min_age&mean_age_1<=max_age)

rma_NFeatures_agesub <- rma.mv(g_calc, g_var_calc, mods = ~as.numeric(n_feature), data = dat_fage, random = ~collapse | short_cite)
 
 sum_eff1 <- coef(summary(rma_NFeatures_agesub))[2,]

rma_AGENFeatures_agesub <- rma.mv(g_calc, g_var_calc, mods = ~as.numeric(n_feature)*age.C, data = dat_fage, random = ~collapse | short_cite)
 
 sum_eff2 <- coef(summary(rma_AGENFeatures_agesub))[4,]

```

Although all papers included in the dataset also included correct pronunciations, not all papers included all three types of feature changes (i.e. 1-3). The age range for each type of number of features changed was `r with(nfeature_ages, min_age[n_feature == 1])` - `r with(nfeature_ages, max_age[n_feature == 1])` days (*M* = `r with(nfeature_ages, mean_age[n_feature == 1])`) for 1-feature mispronunciations, `r with(nfeature_ages, min_age[n_feature == 2])` - `r with(nfeature_ages, max_age[n_feature == 2])` days (*M* = `r with(nfeature_ages, mean_age[n_feature == 2])`) for 2-feature mispronunciations, and `r with(nfeature_ages, min_age[n_feature == 3])` - `r with(nfeature_ages, max_age[n_feature == 3])` days (*M* = `r with(nfeature_ages, mean_age[n_feature == 3])`) for 3-feature mispronunciations. The reader should note that experimental conditions in which the number of features changed in a mispronunciation was not specified or the number of features changed was not consistent (e.g., one mispronunciation included a 2-feature change whereas another only a 1-feature change) are not included in these totals. An analysis focusing on the ages where all three numbers of features changed were tested (i.e. `r with(nfeature_ages, min_age[n_feature == 3])` - `r with(nfeature_ages, max_age[n_feature == 3])` days), however, did not change the pattern of results.

### Distractor familiarity

```{r DistractorType_misp}

rma_Distractor_MP <- rma.mv(g_calc, g_var_calc, mods = ~as.factor(object_pair), data = db_ET_MP, random = ~ collapse | short_cite)

misp_recog <- coef(summary(rma_Distractor_MP))[2,]


rma_Distractor <- rma.mv(g_calc, g_var_calc, mods = ~condition*as.factor(object_pair), data = dat, random = ~ collapse | short_cite)

misp_MS <- coef(summary(rma_Distractor))[4,]


```

We next assessed whether distractor familiarity has an impact on the size of mispronunciation sensitivity. First, we calculated the meta-analytic effect for object identification in response to mispronounced target words/images that were paired with either a familiar or an unfamiliar distractor image. The moderator test was not significant `r mod_test(rma_Distractor_MP)` and the estimate for distractor familiarity was relatively small, $\beta$`r full_estimate(misp_recog)`. This suggests that upon hearing a mispronunciation, infants' looks to the target image were similar for when the target image was paired with an image of a familiar or unfamiliar object. We next assessed whether distractor familiarity was related to mispronunciation sensitivity. We merged the two datasets and included condition (correct pronunciation, mispronunciation) as an additional moderator. The moderator test was significant, `r mod_test(rma_Distractor)`, but the estimate for the interaction between distractor familiarity and condition was small and not significant $\beta$`r full_estimate(misp_MS)`. This relationship is plotted in Figure 4. The results suggest that overall, infants' familiarity with the distractor object (familiar or unfamiliar) did not impact their mispronunciation sensitivity.

## Figure 4

```{r PlotDistFamEffect_NoAge}


dat$condition_label = ifelse(dat$condition==1, "Correct", "Mispronunciation")
dat$dist_code <- ifelse(dat$object_pair == "familiar_familiar", "Familiar Distractor", "Unfamiliar Distractor")

# Color Blind palette:
cbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

p.DIST_ALL <- ggplot(dat, aes(condition_label, g_calc, fill = condition_label)) + 
  geom_violin() + 
  geom_jitter(height = 0, width = 0.1, alpha = 0.5)+
  facet_grid(.~dist_code) +
  #labs(caption="a.") + 
  #geom_smooth(method = "lm", formula = y ~ log(x), aes(weight=weights_g)) + 
  scale_fill_manual(values=cbPalette)+
  apatheme +
  theme(text = element_text(size=25),
        legend.title = element_blank(),
        legend.position = "bottom",
        axis.title.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) + 
  #xlab("Number of Features Changed") + 
  geom_hline(yintercept = 0, linetype="dotted") + 
  ylab("Effect size Hedges' g")

p.DIST_ALL

# lay <- rbind(c(1,1,2),
#       c(3,3,3))

  jpeg(filename = "figures/Figure_4_Distractor_Familiarity.jpg", 
       width = 500, height = 300, units = "px")
  
p.DIST_ALL

dev.off()


```

```{r DistractorTypeAge}

rma_DistractorAge <- rma.mv(g_calc, g_var_calc, mods = ~age.C*as.factor(object_pair), data = db_ET_MP, random = ~ collapse | short_cite)

sum_eff <- coef(summary(rma_DistractorAge))[4,]


rma_DistractorAgeMS <- rma.mv(g_calc, g_var_calc, mods = ~age.C*condition*as.factor(object_pair), data = dat, random = ~ collapse | short_cite)
  
#summary(rma_DistractorAgeMS)  

sum_eff1 <- coef(summary(rma_DistractorAgeMS))[8,]
sum_eff2 <- coef(summary(rma_DistractorAgeMS))[7,]

```



We next examined whether age modulates object recognition or mispronunciation sensitivity when the distractor image is familiar or unfamiliar. Based on previous results, we expected older infants to look less to the target in response to mispronunciations and to have greater mispronunciation sensitivity than younger infants when the distractor was unfamiliar compared to familiar. For object recognition in response to a mispronunciation, including age as a moderator resulted in a moderator test that was not significant `r mod_test(rma_DistractorAge)`, and a small estimate for the interaction between age and object recognition ($\beta$`r full_estimate(sum_eff1)`. This suggests that upon hearing a mispronunciation, infant looks to the target image were similar for when the target image was paired with an image of a familiar or unfamiliar object, regardless of their age. We next assessed whether the relationship between distractor familiarity and mispronunciation sensitivity was modulated by age. We merged the two datasets and included condition (correct pronunciation, mispronunciation) as well as age as additional moderators. The moderator test was significant `r mod_test(rma_DistractorAgeMS)`. The estimate for the  three-way-interaction between condition, distractor familiarity, and age was small and not significant ($\beta$ = `r full_estimate(sum_eff1)`. We note that in this model, the interaction between condition and distractor familiarity was significant ($\beta$`r full_estimate(sum_eff2)`, this estimate is similar to the original estimate specifically examining this interaction in a previous model. Taken together, these results suggest that regardless of age, mispronunciation sensitivity was similar whether the distractor image was familiar or unfamiliar.

```{r DistractorTypeAgeRangeSubset}

object_pair_ages <- dat %>%
  group_by(object_pair) %>%
  summarize(min_age = r2(min(mean_age_1, na.rm=TRUE)),
            max_age = r2(max(mean_age_1, na.rm=TRUE)),
            mean_age = r2(mean(mean_age_1, na.rm=TRUE)),
            sd_age = r2(sd(mean_age_1, na.rm=TRUE)))


fn <- subset(dat, object_pair=="familiar_novel")

ff <- subset(dat, object_pair=="familiar_familiar")

age_diff_dist <- t.test(fn$mean_age_1, ff$mean_age_1, paired = F)

#t.test(fn$mean_age_1, ff$mean_age_1)

opa <- as.data.frame(object_pair_ages)
min_age <- max(opa$min_age)
max_age <- min(opa$max_age)


dat_age_MP= db_ET_MP%>%
  filter(mean_age_1>=min_age&mean_age_1<=max_age)

rma_Distractor_MP_agesub <- rma.mv(g_calc, g_var_calc, mods = ~as.factor(object_pair), data = dat_age_MP, random = ~ collapse | short_cite)

misp_recog_agesub <- round(coef(summary(rma_Distractor_MP_agesub))[2,], 2)


rma_DistractorAge_agesub <- rma.mv(g_calc, g_var_calc, mods = ~age.C*as.factor(object_pair), data = dat_age_MP, random = ~ collapse | short_cite)
  
#summary(rma_Distractor_MP)  

misp_MS_agesub <- round(coef(summary(rma_DistractorAge_agesub))[4,], 2)

# misp sensitivity
dat_age= dat%>%
  filter(mean_age_1>=min_age&mean_age_1<=max_age)

rma_Distractor_MS_agesub <- rma.mv(g_calc, g_var_calc, mods = ~as.factor(object_pair)*condition, data = dat_age, random = ~ collapse | short_cite)

misp_recog_Age_agesub <- round(coef(summary(rma_Distractor_MS_agesub))[4,], 2)


rma_DistractorAgeMS_agesub <- rma.mv(g_calc, g_var_calc, mods = ~age.C*condition*as.factor(object_pair), data = dat_age, random = ~ collapse | short_cite)
  
misp_MS_Age_agesub <- round(coef(summary(rma_DistractorAgeMS_agesub))[8,], 2)

  
#summary(rma_Distractor_MS)  
```

Although we anticipated that older children may be more impacted by the presence of a unfamiliar compared to familiar distractor image, we found that age and distractor familiarity did not impact mispronunciation sensitivity. Inspection of the ages tested using different kinds of distractors, however, revealed differences. Infants tested using a familiar distractor were younger (*M* = `r with(object_pair_ages, mean_age[object_pair == "familiar_familiar"])` days, *SD* = `r with(object_pair_ages, sd_age[object_pair == "familiar_familiar"])`, range = `r with(object_pair_ages, min_age[object_pair == "familiar_familiar"])` - `r with(object_pair_ages, max_age[object_pair == "familiar_familiar"])`) than those infants tested using an unfamiliar distractor (*M* = `r with(object_pair_ages, mean_age[object_pair == "familiar_novel"])` days, *SD* = `r with(object_pair_ages, sd_age[object_pair == "familiar_novel"])`, range = `r with(object_pair_ages, min_age[object_pair == "familiar_novel"])` - `r with(object_pair_ages, max_age[object_pair == "familiar_novel"])`), which a two-sample t-test revealed to be a significant difference, *t*(`r r2(age_diff_dist$parameter)`) = `r r2(age_diff_dist$statistic)`, *p* `r psig(age_diff_dist$p.value)`).

[CHRISTINA] CAN YOU TURN THE NUMBERS INTO R CODE HERE? aLSO, NOT SURE WE NEED A T-TEST TO CONFIRM THE OBVIOUS.
[Katie: Is the t-test okay?]

To ensure that the lack of a difference wasn't due to the ages of infants tested with different types of distractors, we repeated the previous model analyses on a subset of papers that tested infants at ages where both familiar and unfamiliar distractors were used (`r min_age` - `r max_age` days). We first considered object recognition is response to a mispronunciation. Here, the pattern of results for the subset of infants was similar to that of the entire dataset; the moderator test was not significant `r mod_test(rma_Distractor_MP_agesub)` and the estimate for distractor familiarity was small, $\beta$`r full_estimate(misp_recog_agesub)`. However, it should be noted that although small, the effect size estimate for distractor familiarity doubled from $\beta$`r r2(misp_recog$estimate)` in the entire dataset to $\beta$`r r2(misp_recog_agesub$estimate)` in the subset. We next assessed the relationship between distractor familiarity and mispronunciation sensitivity. Similar to the analysis with the entire dataset, the moderator test was significant `r mod_test(rma_Distractor_MS_agesub)`. Unlike the analysis with the entire dataset, however, the estimate for the interaction between distractor familiarity and condition was significant $\beta$`r full_estimate(misp_recog_Age_agesub)`, but small and similar to the estimate for this interaction in the full dataset $\beta$ = `r r2(misp_MS$estimate)`.

Although the age range is relatively small in the subset of infant ages tested with both familiar and unfamiliar distractors (`r r2(max_age/30.44 - min_age/30.44)` months), these ages span the beginning of the vocabulary spurt. Considering infants' object looking behavior may be influenced by whether the label for the object is known (Schafer & Plunkett, 1998), however, this age range may still be informative for understanding the role of distractor familiarity on mispronunciation sensitivity and whether this is modulated by age. Similar to the full dataset, however, including age as a moderator of object recognition in response to familiar and unfamiliar distractors resulted in a moderator test that was not significant `r mod_test(rma_DistractorAge_agesub)`, and a small estimate for the interaction between age and object recognition ($\beta$`r full_estimate(misp_MS_agesub)`. Finally, we assessed whether the relationship between distractor familiarity and mispronunciation sensitivity was modulated by age in the subset of data. Again, similar to the full dataset, the moderator test was not significant `r mod_test(rma_DistractorAgeMS_agesub)` and the estimate for the three-way-interaction between condition, distractor familiarity, and age was small and not significant ($\beta$ = `r full_estimate(misp_MS_Age_agesub)`.

[Katie: ultimately, the subset analysis doesn't show anything :( What conclusions can we draw?]



### Phonological overlap between target and distractor

```{r DistractorOverlap_descrip}

dist_overlap_info <- dat %>%
  group_by(distractor_overlap) %>%
  summarize(n_exp_conditions =  n())

```

To assess whether phonological overlap between the target and distractor image labels has an impact on the size of mispronunciation sensitivity, we examined the meta-analytic effect for object identification in response to mispronunciations and mispronunciation sensitivity when the target-distractor pairs either had no overlap or shared the same onset phoneme. We did not include data for which the overlap included both the onset and medial phonemes (*n* = `r with(dist_overlap_info, n_exp_conditions[distractor_overlap == "onset/medial"])`), coda phonemes (*n* = `r with(dist_overlap_info, n_exp_conditions[distractor_overlap == "coda"])`), or for targets paired with an unfamiliar distractor image `r with(dist_overlap_info, n_exp_conditions[distractor_overlap == "novel"])`. The analysis was therefore based on a subset of the overall dataset, with `r with(dist_overlap_info, n_exp_conditions[distractor_overlap == "onset"])` experimental conditions containing onset phoneme overlap between the target and distractor and `r with(dist_overlap_info, n_exp_conditions[distractor_overlap == "no"])` containing no overlap between target and distractor.

[CHRISTINA] SEEMS OK BUT I AM CONFUSED WHY OVERLAP IS THE BASELINE AND WHY YOU BRING IN NOVEL. I THINK YOU NEED TO SPELL THIS OUT MORE. 

[KATIE: I think we had talked about it and decided to include novel. I don't think it needs to be here necessarily, so I'll take it out, especially if its confusing.]


```{r DistractorOverlap}
db_ET_MPo = db_ET_MP %>%
  filter(distractor_overlap == "onset"  |  distractor_overlap == "no")

db_ET_MPo$distractor_overlap <- factor(db_ET_MPo$distractor_overlap, levels = c("onset", "no"))


rma_DistractorOverlap <- rma.mv(g_calc, g_var_calc, mods = ~distractor_overlap, data = db_ET_MPo, random = ~ collapse | short_cite)
  
#summary(rma_DistractorOverlap)  
sum_eff1 <- coef(summary(rma_DistractorOverlap))[2,]


db_ET_MPo_MS = dat %>%
  filter(distractor_overlap == "onset"  | distractor_overlap == "no")

db_ET_MPo_MS$distractor_overlap <- factor(db_ET_MPo_MS$distractor_overlap, levels = c("onset", "no"))


rma_DistractorOverlapMS <- rma.mv(g_calc, g_var_calc, mods = ~condition*distractor_overlap, data = db_ET_MPo_MS, random = ~ collapse | short_cite)

#summary(rma_DistractorOverlapMS)

sum_eff2 <- coef(summary(rma_DistractorOverlapMS))[4,]

```


Regarding object identification in response to mispronunciations, when distractor overlap was included as a moderator, the moderator test was not significant `r mod_test(rma_DistractorOverlap)` and the estimate for distractor overlap was relatively small, $\beta$`r full_estimate(sum_eff1)`. This suggests that upon hearing a mispronunciation, infants looks to the target image were similar for when the target image was paired with a distractor image that contained overlap on the onset phoneme or no overlap with the target word, or was an unfamiliar object. We next assessed whether target-distractor overlap was related to mispronunciation sensitivity. We merged the two datasets and included condition (correct pronunciation, mispronunciation) as an additional moderator. The moderator test was significant `r mod_test(rma_DistractorOverlapMS)`. The estimate for the interaction between condition and distractor overlap was small, but significant ($\beta$ `r full_estimate(sum_eff2)`, suggesting that mispronunciation sensitivity was greater when target-distractor pairs shared the same onset phoneme compared to when they shared no phonological overlap. This relationship be seen in Figure 5a. 


```{r DistractorOverlap_age}

# object recognition
db_ET_MPo = db_ET_MP %>%
  filter(distractor_overlap == "onset"  | distractor_overlap == "no")

db_ET_MPo$distractor_overlap <- factor(db_ET_MPo$distractor_overlap, levels = c("onset", "no"))

rma_DistractorOverlap_age <- rma.mv(g_calc, g_var_calc, mods = ~age.C*distractor_overlap, data = db_ET_MPo, random = ~ collapse | short_cite)
  
sum_eff1 <- coef(summary(rma_DistractorOverlap_age))[4,]


# mispronunciation sensitivity
dat_MPo = dat %>%
  filter(distractor_overlap == "onset"  | distractor_overlap == "no")

dat_MPo$distractor_overlap <- factor(dat_MPo$distractor_overlap, levels = c("onset", "no"))

rma_DistractorOverlap_age_MS <- rma.mv(g_calc, g_var_calc, mods = ~age.C*distractor_overlap*condition, data = dat_MPo, random = ~ collapse | short_cite)
  
#summary(rma_DistractorOverlap_age_MS)

sum_eff2 <- coef(summary(rma_DistractorOverlap_age_MS))[8,]

```

Although we did not have any specific predictions about the relationship between infant age and the impact of distractor overlap on mispronunciation sensitivity, we included an exploratory analysis to examine this relationship. First, for object recognition in response to mispronunciations, when age in addition to distractor overlap was also included as a moderator, the moderator test was not significant, `r mod_test(rma_DistractorOverlap_age)`, and the estimate for the interaction between age and distractor overlap was small, $\beta$`r full_estimate(sum_eff1)`. This suggests that upon hearing a mispronunciation, infants looks to the target image were similar for both onset and no overlap, regardless of infant age. We next assessed whether the relationship between distractor overlap and mispronunciation sensitivity was modulated by age. We merged the two datasets and included condition (correct pronunciation, mispronunciation) as well as age as additional moderators. The moderator test was significant, `r mod_test(rma_DistractorOverlap_age_MS)` and the estimate for the three-way interaction between age, condition, and distractor overlap was significant, but relatively small ($\beta$ = `r full_estimate(sum_eff2)`. As can be seen in Figure 5b, the difference between correct pronunciations and mispronunciations (mispronunciation sensitivity) stays steady across infant ages for both target words paired with distractors containing onset overlap with the target word as well as distractors containing no overlap. As infants aged, however, overall recognition (regardless of condition) increased for target-distractor pairs containing onset overlap, whereas for overall recognition decreased for target-distractor pairs containing no overlap. 

## Figure 5

```{r PlotDistOverlap_cond_age}

db_ET_MPo = dat %>%
  filter(distractor_overlap == "onset"  | distractor_overlap == "no")

db_ET_MPo$distractor_overlap <- factor(db_ET_MPo$distractor_overlap, levels = c("onset", "no"))

db_ET_MPo$condition_label <- ifelse(db_ET_MPo$condition==1, "Correct", "Mispronunciation")

db_ET_MPo$distractor_label <- ifelse(db_ET_MPo$distractor_overlap=="onset", "Onset Overlap", "No Overlap")


p.DIOV_M <- ggplot(db_ET_MPo, aes(condition_label, g_calc, fill = condition_label)) + 
  facet_grid(.~distractor_label)+
    geom_violin() + 
  geom_jitter(height = 0, width = 0.1, alpha = 0.5)+
  labs(caption="a")+
  #geom_smooth(method = "lm", formula = y ~ log(x), aes(weight=weights_g)) + 
  scale_fill_manual(values=cbPalette)+
  apatheme +
  theme(text = element_text(size=25),
        legend.title = element_blank(),
        legend.position = "bottom",
        axis.title.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) + 
  #xlab("Number of Features Changed") + 
  geom_hline(yintercept = 0, linetype="dotted") + 
  ylab("Effect size Hedges' g")



p.DIOV_AGE <- ggplot(db_ET_MPo, aes(mean_age_1/30.44, g_calc, color = condition_label)) + 
    facet_grid(.~distractor_label)+
  geom_point(aes(size = weights_g),show.legend=FALSE) +
  labs(caption="b")+
  geom_line(y= 0, linetype="dotted") + 
  geom_smooth(method = "lm", formula = y ~ log(x), aes(weight=weights_g)) +
  scale_colour_manual(values=cbPalette)+
  apatheme +
  theme(legend.title = element_blank(),
        legend.position = "bottom") + 
  xlab("Age in months") + 
  ylab("Effect size Hedges' g")


lay <- rbind(c(1), c(2))

  jpeg(filename = "figures/Figure_5_Distractor_overlap_age.jpg", 
       width = 500, height = 600, units = "px")
  
ger.plot.age <- grid.arrange(p.DIOV_M, p.DIOV_AGE,
                             layout_matrix = lay)

dev.off()

  
```

### Position of mispronunciation

```{r Location_descrip}

misp_location_info <- dat %>%
  group_by(mispron_location) %>%
  summarize(n_exp_conditions =  n())


```

To assess whether the position of the mispronunciation has an impact on mispronunciation sensitivity, we calculated the meta-analytic effect for object identification in response to mispronunciations on the onset and medial phonemes. We did not include data for which the mispronunciation was located on the coda (*n* = `r with(misp_location_info, n_exp_conditions[mispron_location == "coda"])`), varied in regard to position (*n* = `r with(misp_location_info, n_exp_conditions[mispron_location == "coda/medial" | mispron_location == "onset/medial" | mispron_location == "onset/medial/coda"])`), or was not reported (*n* = `r with(misp_location_info, n_exp_conditions[is.na(mispron_location)])`). The analysis was therefore based on a subset of the overall dataset, with `r with(misp_location_info, n_exp_conditions[mispron_location == "onset"])` experimental conditions comparing a mispronunciation on the onset phoneme and `r with(misp_location_info, n_exp_conditions[mispron_location == "medial"])` experimental conditions comparing a mispronunciation on the medial phoneme.

```{r Location_misp}
#table(db_ET_MP$mispron_location)

db_ET_MPl = db_ET_MP %>%
  filter(mispron_location == "onset"  | mispron_location == "medial")

db_ET_MPl$mispron_location <- factor(db_ET_MPl$mispron_location, levels = c("onset", "medial"))

#rma_NFeatures <- rma.mv(g_calc, g_var_calc, mods = ~as.ordered(n_feature), data = db_ET_MP, random = ~collapse | short_cite)
rma_Location_MP <- rma.mv(g_calc, g_var_calc, mods = ~mispron_location, data = db_ET_MPl, random = ~collapse | short_cite)

sum_eff2 <- coef(summary(rma_Location_MP))[2,]
 



db_ET_MPl = dat %>%
  filter(mispron_location == "onset"  | mispron_location == "medial")

db_ET_MPl$mispron_location <- factor(db_ET_MPl$mispron_location, levels = c("onset", "medial"))

rma_LocationCondition <- rma.mv(g_calc, g_var_calc, mods = ~mispron_location*condition, data = db_ET_MPl, random = ~collapse | short_cite)
 
sum_eff2 <- coef(summary(rma_LocationCondition))[4,]


```


Regarding object identification in response to mispronunciations, when mispronunciation location was included as a moderator, the moderator test was not significant `r mod_test(rma_Location_MP)` and the estimate for distractor overlap was small, $\beta$`r full_estimate(sum_eff1)`. This suggests that upon hearing a mispronunciation, infants looks to the target image were similar for when the mispronunciation was located on the onset or  medial phonemes. We next assessed whether mispronunciation location was related to mispronunciation sensitivity. We merged the two datasets and included condition (correct pronunciation, mispronunciation) as an additional moderator. The moderator test was significant, `r mod_test(rma_LocationCondition)`, but the estimate for the interaction between mispronunciation location and condition was small and not significant, $\beta$`r full_estimate(sum_eff2)`. These results suggest that overall, the location of the mispronunciation (onset, medial) did not impact mispronunciation sensitivity.

```{r PlotPositionEffect}

# #dat.p <- subset(dat, mispron_location == "onset" | mispron_location == "medial" |
# #                mispron_location == "offset")
# 
# dat$condition_label = ifelse(dat$condition==1, "Correct", "Mispronunciation")
# 
# dat.p = dat %>%
#   filter(mispron_location == "onset"  | mispron_location == "medial")
# 
# dat.p$mispron_location <- factor(dat.p$mispron_location, levels = c("onset", "medial"))
# 
# 
# p <- ggplot(dat.p, aes(condition_label, g_calc, fill = condition_label)) + 
#   facet_grid(.~mispron_location)+
#   geom_boxplot() + 
#   #geom_smooth(method = "lm", formula = y ~ log(x), aes(weight=weights_g)) + 
#   scale_fill_manual(values=cbPalette)+
#   apatheme +
#   theme(text = element_text(size=25),
#         legend.title = element_blank(),
#         legend.position = "bottom",
#         axis.title.x = element_blank(),
#         axis.text.x = element_blank(),
#         axis.ticks.x = element_blank()) + 
#   #xlab("Number of Features Changed") + 
#   geom_hline(yintercept = 0, linetype="dotted") + 
#   ylab("Effect size Hedges' g")
# 
# p
# 
#   jpeg(filename = "figures/Figure_7_Mispronunciation_position.jpg", 
#        width = 500, height = 300, units = "px")
# 
#   p
#   
#   dev.off()


```

```{r Location_misp_age}
#table(db_ET_MP$mispron_location)

db_ET_MPl = db_ET_MP %>%
  filter(mispron_location == "onset"  | mispron_location == "medial")

db_ET_MPl$mispron_location <- factor(db_ET_MPl$mispron_location, levels = c("onset", "medial"))

#rma_NFeatures <- rma.mv(g_calc, g_var_calc, mods = ~as.ordered(n_feature), data = db_ET_MP, random = ~collapse | short_cite)
rma_Location_MP_age <- rma.mv(g_calc, g_var_calc, mods = ~mispron_location*age.C, data = db_ET_MPl, random = ~collapse | short_cite)
 
sum_eff1 <- coef(summary(rma_Location_MP_age))[4,]



db_ET_MPl = dat %>%
  filter(mispron_location == "onset"  | mispron_location == "medial")

db_ET_MPl$mispron_location <- factor(db_ET_MPl$mispron_location, levels = c("onset", "medial"))

rma_LocationCondition_age <- rma.mv(g_calc, g_var_calc, mods = ~mispron_location*condition*age.C, data = db_ET_MPl, random = ~collapse | short_cite)
 
sum_eff2 <- coef(summary(rma_LocationCondition))[8,]


```

According to TRACE, infants should become more sensitive to onset mispronunciations as their lexicon size grows, but sensitivity to medial mispronunciations should stay the same (Mayor & Plunkett, 2014). To examine this relationship, we included age as a moderator. First, for object recognition in response to mispronunciations, when age in addition to mispronunciation location was also included as a moderator, the moderator test was not significant, `r mod_test(rma_Location_MP)` and the estimate for the interaction between distractor overlap and age was small, $\beta$`r full_estimate(sum_eff1)`. This suggests that upon hearing a mispronunciation, infants looks to the target image were similar for both onset and medial mispronunciations, regardless of infant age. We next assessed whether the relationship between mispronunciation location and mispronunciation sensitivity was modulated by age. We merged the two datasets and included condition (correct pronunciation, mispronunciation) as well as age as additional moderators. The moderator test was significant, `r mod_test(rma_LocationCondition)`, but the estimate for the three-way interaction between mispronunciation loction, condition, and age was small and not significant, $\beta$`r full_estimate(sum_eff2)`. These results provide further evidence that location of the mispronunciation (onset, medial) did not impact mispronunciation sensitivity.

```{r MispLocationAgeRangeSubset}

misp_location_ages <- dat %>%
  group_by(mispron_location) %>%
  summarize(min_age = r2(min(mean_age_1, na.rm=TRUE)),
            max_age = r2(max(mean_age_1, na.rm=TRUE)),
            mean_age = r2(mean(mean_age_1, na.rm=TRUE)),
            sd_age = r2(sd(mean_age_1, na.rm=TRUE)))


fn <- subset(dat, mispron_location=="onset")

ff <- subset(dat, mispron_location=="medial")

age_misp_location <- t.test(fn$mean_age_1, ff$mean_age_1, paired = F)

#t.test(fn$mean_age_1, ff$mean_age_1)

mla <- as.data.frame(misp_location_ages)
mla <- subset(mla, mispron_location == "onset"  | mispron_location == "medial")
min_age <- max(mla$min_age)
max_age <- min(mla$max_age)


dat_age_MP= db_ET_MP%>%
  filter(mean_age_1>=min_age&mean_age_1<=max_age)

dat_age_MP = dat_age_MP %>%
  filter(mispron_location == "onset"  | mispron_location == "medial")

dat_age_MP$mispron_location <- factor(dat_age_MP$mispron_location, levels = c("onset", "medial"))

rma_Location_MP_agesub <- rma.mv(g_calc, g_var_calc, mods = ~as.factor(mispron_location), data = dat_age_MP, random = ~ collapse | short_cite)

misp_recog_agesub <- coef(summary(rma_Location_MP_agesub))[1,]


rma_LocationAge_agesub <- rma.mv(g_calc, g_var_calc, mods = ~age.C*as.factor(mispron_location), data = dat_age_MP, random = ~ collapse | short_cite)
  
#summary(rma_Location_MP)  

misp_MS_agesub <- coef(summary(rma_LocationAge_agesub))[4,]




# misp sensitivity
dat_age= dat%>%
  filter(mean_age_1>=min_age&mean_age_1<=max_age)

dat_age = dat_age %>%
  filter(mispron_location == "onset"  | mispron_location == "medial")

dat_age$mispron_location <- factor(dat_age$mispron_location, levels = c("onset", "medial"))


rma_Location_MS_agesub <- rma.mv(g_calc, g_var_calc, mods = ~as.factor(mispron_location)*condition, data = dat_age, random = ~ collapse | short_cite)

misp_recog_Age_agesub <- coef(summary(rma_Location_MS_agesub))[4,]


rma_LocationAgeMS_agesub <- rma.mv(g_calc, g_var_calc, mods = ~age.C*condition*as.factor(mispron_location), data = dat_age, random = ~ collapse | short_cite)
  
misp_MS_Age_agesub <- coef(summary(rma_LocationAgeMS_agesub))[8,]

  
#summary(rma_Distractor_MS)  
```

Although we anticipated that older children may be more impacted by the position of a mispronunciation, we found no relationship. Inspection of the ages tested using on onset and medial mispronunciations, however, revealed differences. Infants tested on onset mispronunciations were older (*M* = `r with(misp_location_ages, mean_age[mispron_location == "onset"])` days, *SD* = `r with(misp_location_ages, sd_age[mispron_location == "onset"])`, range = `r with(misp_location_ages, min_age[mispron_location == "onset"])` - `r with(misp_location_ages, max_age[mispron_location == "onset"])`) than those infants tested on medial mispronunciations (*M* = `r with(misp_location_ages, mean_age[mispron_location == "medial"])` days, *SD* = `r with(misp_location_ages, sd_age[mispron_location == "medial"])`, range = `r with(misp_location_ages, min_age[mispron_location == "medial"])` - `r with(misp_location_ages, max_age[mispron_location == "medial"])`), which a two-sample t-test revealed to be a significant difference, *t*(`r r2(age_misp_location$parameter)`) = `r r2(age_misp_location$statistic)`, *p* `r psig(age_misp_location$p.value)`).

To ensure that the lack of a difference wasn't due to the ages of infants tested with onset and medial mispronunciations, we repeated the previous model analyses on a subset of papers that tested infants at ages where onset and medial mispronunciations were tested (`r min_age` - `r max_age` days). The analyses on this subset of data did not differ from that of the analyses conducted on the entire data set.

[Katie: ultimately, the subset analysis doesn't show anything :( What conclusions can we draw?]


### Type of mispronunciation (consonant or vowel)

```{r CV_descript}

CV_info <- dat %>%
  group_by(type_feature) %>%
  summarize(n_exp_conditions =  n())

CV_location_info <- dat %>%
  group_by(type_feature, mispron_location) %>%
  summarize(n_exp_conditions =  n())

```

To assess whether the type of mispronunciation impacts sensitivity to mispronunciations, we calculated the meta-analytic effect for object identification in response to the type of mispronunciation. Although most theoretical discussion of mispronunciation type has focused on consonants and vowels, our dataset also included tone mispronunciations. In our analysis, we were interested in the difference between consonants and vowels, but also include an exploratory analysis of responses to tones, consonants, and vowels. We therefore conducted two sets of analyses, one analyzing consonants and vowels alone and a second comparing responses to tones with that of consonants and vowels, separately. For the latter analysis, tones were coded as the reference condition. We did not include data for which mispronunciation type varied within experiment and was not reported separately (*n* = `r with(CV_info, n_exp_conditions[type_feature == "consonant_and_vowel" | type_feature == "consonant_vowel_tone"])`). The analysis was therefore based on a subset of the overall dataset, with `r with(CV_info, n_exp_conditions[type_feature == "consonant"])` experimental conditions comparing a consonant mispronunciation, `r with(CV_info, n_exp_conditions[type_feature == "vowel"])` experimental conditions comparing a vowel mispronunciation, and `r with(CV_info, n_exp_conditions[type_feature == "tone"])` experimental conditions comparing a tone mispronunciation. Below, we first report the set of analyses comparing consonants with vowels before moving on to the second set of exploratory analyses comparing tones with that of consonants and vowels.

[KATIE] WHAT DO YOU THINK ABOUT THIS? WE HAVE THE TONES AND ITS A NOVEL, INTERESTING THING, I THINK, AND PERHAPS WORTH IT TO INCLUDE A COMPARISON OF TONES ALONGSIDE THE MORE THEORETICALLY IMPORTANT COMPARISON BETWEEN CONSONANTS AND VOWELS.

```{r MPtype_cv}

# C vs. V
db_MP_type <- subset(db_ET_MP, type_feature == "consonant" | type_feature == "vowel")

db_MP_type$type_feature <- factor(db_MP_type$type_feature, levels = c("consonant", "vowel"))

rma_TypeFeaturesMP <- rma.mv(g_calc, g_var_calc, mods = ~type_feature, data = db_MP_type, random = ~collapse | short_cite)
 
sum_eff1 <- coef(summary(rma_TypeFeaturesMP))[2,]



# C vs. V with condition 

db_type <- subset(dat, type_feature == "consonant" | type_feature == "vowel")

db_type$type_feature <- factor(db_type$type_feature, levels = c("consonant", "vowel"))

rma_TypeFeaturesMP_Condition <- rma.mv(g_calc, g_var_calc, mods = ~type_feature*condition, data = db_type, random = ~collapse | short_cite)

sum_eff2 <- coef(summary(rma_TypeFeaturesMP_Condition))[4,]

```


We first analyzed experimental conditions where mispronunciation type was either a consonant or vowel. Regarding object identification in response to mispronunciations, when mispronunciation type was included as a moderator, the moderator test was not significant, `r mod_test(rma_Location_MP)` and the estimate for mispronunciation type was small, $\beta$`r full_estimate(sum_eff1)`. This suggests that upon hearing a mispronunciation, infants looks to the target image were similar for when the mispronunciation was a consonant or a vowel. We next assessed whether type of mispronunciation (consonant or vowel) was related to mispronunciation sensitivity. We merged the two datasets and included condition (correct pronunciation, mispronunciation) as an additional moderator. The moderator test was significant, `r mod_test(rma_LocationCondition)`, but the estimate for the interaction between mispronunciation type and condition was small and not significant, $\beta$`r full_estimate(sum_eff2)`. These results suggest that overall, the type of  mispronunciation (consonant vs. vowel) did not impact mispronunciation sensitivity.


```{r MPtype_cv_age}
db_MP_type <- subset(db_ET_MP, type_feature == "consonant" | type_feature == "vowel" )

db_MP_type$type_feature <- factor(db_MP_type$type_feature, levels = c("consonant", "vowel"))

rma_TypeFeaturesMPage <- rma.mv(g_calc, g_var_calc, mods = ~type_feature*age.C, data = db_MP_type, random = ~collapse | short_cite)
 
sum_eff1 <- coef(summary(rma_TypeFeaturesMPage))[4,]

 

# with condition
db_type <- subset(dat, type_feature == "consonant" | type_feature == "vowel")

db_type$type_feature <- factor(db_type$type_feature, levels = c("consonant", "vowel"))

rma_TypeFeaturesMP_Condition <- rma.mv(g_calc, g_var_calc, mods = ~type_feature*condition*age.C, data = db_type, random = ~collapse | short_cite)

sum_eff2 <- coef(summary(rma_TypeFeaturesMP_Condition))[8,]

```

We next examined whether age modulates object recognition or mispronunciation sensitivity when the mispronunciation is a consonant or vowel. For object recognition in response to a mispronunciation, including age as a moderator resulted in a moderator test that was not significant, `r mod_test(rma_TypeFeaturesMPage)` and the estimate for the interaction between mispronunciation type and age was small, $\beta$`r full_estimate(sum_eff1)`. This suggests that upon hearing a mispronunciation, infants looks to the target image were similar for when the mispronunciation was on a consonant or vowel phoneme, regardless of their age. We next assessed whether the relationship between mispronunciation type (consonant or vowel) and mispronunciation sensitivity was modulated by age. We merged the two datasets and included condition (correct pronunciation, mispronunciation) as well as age as additional moderators. The moderator test was significant, `r mod_test(rma_LocationCondition)`, and the estimate for the three-way interaction between mispronunciation type, condition, and age was small, but significant, $\beta$`r full_estimate(sum_eff2)`. As can be seen in Figure 6, as infants age, mispronunciation sensitivity grows larger for vowel mispronunciations but becomes smaller for consonant mispronunciations. Noticeably, mispronunciation sensitivity appears greater for consonant compared to vowel mispronunciations at younger ages, but this difference shifts as infants age.

## Figure 6

```{r PlotCVEffect_cond_age}

dat_type <- subset(dat, type_feature == "consonant" | type_feature == "vowel" )
dat_type$type_feature <- ifelse(dat_type$type_feature == "consonant", "Consonant", "Vowel")

#db_MP_type <- subset(db_ET_MP, type_feature != "consonant_and_vowel")

#dat_type_sub <- subset(dat_type, lang_family != "Sino-Tibetian")


dat_type$condition_label = ifelse(dat_type$condition==1, "Correct", "Mispronunciation")

p <- ggplot(dat_type, aes(mean_age_1/30.44, g_calc, color = condition_label)) + 
    facet_grid(.~type_feature)+
  geom_point(aes(size = weights_g),show.legend=FALSE) + 
  geom_line(y= 0, linetype="dotted") + 
  geom_smooth(method = "lm", formula = y ~ log(x), aes(weight=weights_g)) +
  scale_colour_manual(values=cbPalette)+
  apatheme +
  theme(legend.title = element_blank(),
        legend.position = "bottom") + 
  xlab("Age in months") + 
  ylab("Effect size Hedges' g")
  
p


  jpeg(filename = "figures/Figure_6_FeatureType_Cond_Age.jpg", 
       width = 500, height = 300, units = "px")

  p
  
  dev.off()
  
```


```{r MPtype_cv_lang_descript}

family <- dat %>%
  group_by(lang_family) %>%
  summarize(count = n())

lang_family <- dat %>%
  group_by(native_lang, lang_family) %>%
  summarize(count = n())

cv_family <- dat %>%
  group_by(type_feature, lang_family) %>%
  summarize(count = n())

```

```{r MPtype_cv_lang}

db_MP_type <- subset(db_ET_MP, type_feature == "consonant" | type_feature == "vowel" )

db_MP_type$type_feature <- factor(db_MP_type$type_feature, levels = c("consonant", "vowel"))

db_MP_type <- subset(db_MP_type, lang_family != "Sino-Tibetian")


rma_TypeFeaturesMPfam <- rma.mv(g_calc, g_var_calc, mods = ~type_feature*lang_family, data = db_MP_type, random = ~collapse | short_cite)
 
sum_eff1 <- coef(summary(rma_TypeFeaturesMPfam))[4,]

 

# with condition
db_type <- subset(dat, type_feature == "consonant" | type_feature == "vowel")

db_type$type_feature <- factor(db_type$type_feature, levels = c("consonant", "vowel"))

db_type <- subset(db_type, lang_family != "Sino-Tibetian")

rma_TypeFeaturesMPC <- rma.mv(g_calc, g_var_calc, mods = ~type_feature*condition*lang_family, data = db_type, random = ~collapse | short_cite)

sum_eff2 <- coef(summary(rma_TypeFeaturesMPC))[7,]
sum_eff3 <- coef(summary(rma_TypeFeaturesMPC))[8,]

# summary(glht(rma_TypeFeaturesMPC, linfct=cbind(contrMat(rep(1,8), type="Tukey"))), test=adjusted("none"))
# 
# ranef(rma_TypeFeaturesMPC)

```

To examine whether infants' native language impacts sensitivity to consonant and vowel mispronunciations, we classified infants into language families. Infants learning American English (*n* = `r with(lang_family, count[native_lang == "American English"])`), British English (*n* = `r with(lang_family, count[native_lang == "British English"])`), Danish (*n* = `r with(lang_family, count[native_lang == "Danish"])`), Dutch (*n* = `r with(lang_family, count[native_lang == "Dutch"])`), and German (*n* = `r with(lang_family, count[native_lang == "German"])`) were classified into the Germanic language family (*n* = `r with(family, count[lang_family == "Germanic"])`). Infants learning Catalan (*n* = `r with(lang_family, count[native_lang == "Catalan"])`), Spanish (*n* = `r with(lang_family, count[native_lang == "Spanish"])`), French (*n* = `r with(lang_family, count[native_lang == "French"])`), Catalan and Spanish simultaneously (i.e. bilinguals; *n* = `r with(lang_family, count[native_lang == "Catalan-Spanish"])`), and Swiss French (*n* = `r with(lang_family, count[native_lang == "Swiss French"])`) were classified into the Romance language family (*n* = `r with(family, count[lang_family == "Romance"])`). 

For object recognition in response to a mispronunciation, including language family as a moderator resulted in a moderator test that was not significant, `r mod_test(rma_TypeFeaturesMPage)`, and the estimate for the interaction between mispronunciation type and language family was small, $\beta$`r full_estimate(sum_eff1)`. This suggests that upon hearing a mispronunciation, infants looks to the target image were similar for when the mispronunciation was on a consonant or vowel phoneme, regardless of the language family of their native language. We next assessed whether the relationship between mispronunciation type (consonant or vowel) and mispronunciation sensitivity was modulated by language family. We merged the two datasets and included condition (correct pronunciation, mispronunciation) as well as language family as additional moderators. The moderator test was significant, `r mod_test(rma_TypeFeaturesMPage)`, and the estimate for the three-way interaction between mispronunciation type, condition, language family was large and significant , $\beta$`r full_estimate(sum_eff3)`. As can be seen in Figure 7, mispronunciation sensitivity for consonants was similar for Germanic and Romance languages. Mispronunciation sensitivity for vowels, however, was greater for Germanic compared to Romance languages.

[KATIE] I'M NOT REALLY SURE WHAT THE CONDITION BY LANGUAGE FAMILY INTERACTION MEANS. SHOULD WE EVEN INTERPRET IT? MAYBE THAT THE ROMANCE LANGUAGE FAMILY HAD LOWER MISPRONUNCIATION SENSITIVITY?

## Figure 7

```{r PlotCVEffect_Lang}

dat_type <- subset(dat, type_feature == "consonant" | type_feature == "vowel" )
dat_type$type_feature <- ifelse(dat_type$type_feature == "consonant", "Consonant", "Vowel")

#db_MP_type <- subset(db_ET_MP, type_feature != "consonant_and_vowel")

dat_type_sub <- subset(dat_type, lang_family != "Sino-Tibetian")


dat_type_sub$condition_label = ifelse(dat_type_sub$condition==1, "Correct", "Mispronunciation")


p <- ggplot(dat_type_sub, aes(condition_label, g_calc, fill = condition_label)) + 
  facet_grid(.~type_feature*lang_family)+
    geom_violin() + 
  geom_jitter(height = 0, width = 0.1, alpha = 0.5)+
  #geom_line(y= 0, linetype="dotted") + 
  #geom_smooth(method = "lm", formula = y ~ log(x), aes(weight=weights_g)) +
    scale_fill_manual(values=cbPalette)+
  apatheme +
  theme(text = element_text(size=25),
        legend.title = element_blank(),
        legend.position = "bottom",
        axis.title.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank()) + 
  #xlab("Number of Features Changed") + 
  geom_hline(yintercept = 0, linetype="dotted") + 
  xlab("Language Family") + 
  ylab("Effect size Hedges' g")
p


 jpeg(filename = "figures/Figure_7_FeatureType_Cond_LangFam.jpg", 
       width = 500, height = 300, units = "px")

  p
  
  dev.off()
  
```

```{r MPtype_cv_lang_age}

db_MP_type <- subset(db_ET_MP, type_feature == "consonant" | type_feature == "vowel" )

db_MP_type$type_feature <- factor(db_MP_type$type_feature, levels = c("consonant", "vowel"))

db_MP_type <- subset(db_MP_type, lang_family != "Sino-Tibetian")


rma_TypeFeaturesMPfam <- rma.mv(g_calc, g_var_calc, mods = ~type_feature*lang_family*age.C, data = db_MP_type, random = ~collapse | short_cite)
 
 sum_eff1 <- coef(summary(rma_TypeFeaturesMPfam))[8,]


# with condition
db_type <- subset(dat, type_feature == "consonant" | type_feature == "vowel")

db_type$type_feature <- factor(db_type$type_feature, levels = c("consonant", "vowel"))

db_type <- subset(db_type, lang_family != "Sino-Tibetian")

rma_TypeFeaturesMPC <- rma.mv(g_calc, g_var_calc, mods = ~type_feature*condition*lang_family*age.C, data = db_type, random = ~collapse | short_cite)

sum_eff2 <- coef(summary(rma_TypeFeaturesMPC))[7,]
sum_eff3 <- coef(summary(rma_TypeFeaturesMPC))[8,]

# summary(glht(rma_TypeFeaturesMPC, linfct=cbind(contrMat(rep(1,8), type="Tukey"))), test=adjusted("none"))
# 
# ranef(rma_TypeFeaturesMPC)

```

Finally, we examined the relationship between language family and infant age and mispronunciation sensitivity to consonants and vowels. For object recognition in response to a mispronunciation, including language family and infant age as a moderator resulted in a moderator test that was significant, `r mod_test(rma_TypeFeaturesMPage)`, and the estimate for the three-way interaction between mispronunciation type, language family, and age was small, but significant , $\beta$`r full_estimate(sum_eff3)`. As can be seen in Figure 8, looks to the target in response to a mispronunciation increased with age for infants learning a Germanic language, regardless of whether those mispronunciations were consonants or vowels. In contrast, infants learning Romance languages have an even greater increase with age in target looks in response to consonant mispronunciations, but there was no change with age for vowel mispronunciations. We next assessed whether the relationship between mispronunciation type (consonant or vowel) and mispronunciation sensitivity was modulated by language family and age. We merged the two datasets and included condition (correct pronunciation, mispronunciation) as well as language family and age as additional moderators. The moderator test was significant, `r mod_test(rma_TypeFeaturesMPC)`, and the estimate for the four-way interaction between mispronunciation type, condition, language family, and age was small, but significant , $\beta$`r full_estimate(sum_eff3)`. As can also be seen in Figure 8, for infants learning Germanic languages, increasing age was related to increasing mispronunciation sensitivity for vowel mispronunciations, but decreasing sensitivity for consonant mispronunciations. In contrast, infants learning Romance languages have an even greater increase with age in sensitivity to vowel mispronunciations. Surprisingly, sensitivity to consonant mispronunciations shows a reversal in infants learning Romance languages: the growth in target looks for consonant mipronunciations increases and surpases that of target looks for correct pronunciations.

[KATIE] AGAIN, THERE ARE ADDITIONAL INTERACTIONS THAT ARE SIGNIFICANT... SHOULD THEY BE INTERPRETED? ALSO, WTF ROMANCE LANGUAGES? IS IT JUST NOT ENOUGH DATA?

## Figure 8

```{r PlotCVEffect_cond_age_fam}

dat_type <- subset(dat, type_feature == "consonant" | type_feature == "vowel" )
dat_type$type_feature <- ifelse(dat_type$type_feature == "consonant", "Consonant", "Vowel")

#db_MP_type <- subset(db_ET_MP, type_feature != "consonant_and_vowel")

dat_type_sub <- subset(dat_type, lang_family != "Sino-Tibetian")


dat_type_sub$condition_label = ifelse(dat_type_sub$condition==1, "Correct", "Mispronunciation")

p <- ggplot(dat_type_sub, aes(mean_age_1/30.44, g_calc, color = condition_label)) + 
    facet_grid(.~type_feature*lang_family)+
  geom_point(aes(size = weights_g),show.legend=FALSE) + 
  geom_line(y= 0, linetype="dotted") + 
  geom_smooth(method = "lm", formula = y ~ log(x), aes(weight=weights_g)) +
  scale_colour_manual(values=cbPalette)+
  apatheme +
  theme(legend.title = element_blank(),
        legend.position = "bottom") + 
  xlab("Age in months") + 
  ylab("Effect size Hedges' g")
  
p


  jpeg(filename = "figures/Figure_8_FeatureType_Cond_Age_LangFam.jpg", 
       width = 500, height = 300, units = "px")

  p
  
  dev.off()
  
```


```{r MPtype_cvt}

# C vs. V vs. T
db_MP_type <- subset(db_ET_MP, type_feature == "consonant" | type_feature == "vowel" | type_feature == "tone")

db_MP_type$type_feature <- factor(db_MP_type$type_feature, levels = c("tone", "consonant", "vowel"))

rma_TypeFeaturesMPT <- rma.mv(g_calc, g_var_calc, mods = ~type_feature, data = db_MP_type, random = ~collapse | short_cite)
 
# C vs. V vs. T with condition 

db_type <- subset(dat, type_feature == "consonant" | type_feature == "vowel"| type_feature == "tone")

db_type$type_feature <- factor(db_type$type_feature, levels = c("tone", "consonant", "vowel"))

rma_TypeFeaturesMP_ConditionT <- rma.mv(g_calc, g_var_calc, mods = ~type_feature*condition, data = db_type, random = ~collapse | short_cite)

sum_eff2c <- coef(summary(rma_TypeFeaturesMP_ConditionT))[5,]
sum_eff2v <- coef(summary(rma_TypeFeaturesMP_ConditionT))[6,]


```


Although we had no predictions regarding mispronunciation sensitivity to tone mispronunciations, we included an exploratory analysis to examine whether responses to tone mispronunciations were different from that of consonants or vowels. Regarding object identification in response to mispronunciations, when mispronunciation type was included as a moderator, the moderator test was not significant QM(`r r2(rma_TypeFeaturesMPT$m)`) = `r r2(rma_TypeFeaturesMPT$QM)`, *p* `r psig(rma_TypeFeaturesMPT$QMp)`. This suggests that upon hearing a mispronunciation, infants looks to the target image were similar for tone mispronunciations in comparison with both consonants and vowels. We next assessed whether type of mispronunciation (tone, consonant, vowel) was related to mispronunciation sensitivity. We merged the two datasets and included condition (correct pronunciation, mispronunciation) as an additional moderator. The moderator test was significant, QM(`r r2(rma_TypeFeaturesMP_ConditionT$m)`) = `r r2(rma_TypeFeaturesMP_ConditionT$QM)`, *p* `r psig(rma_TypeFeaturesMP_ConditionT$QMp)`. The interaction between condition and consonant mispronunciations was not significant $\beta$ = `r r2(sum_eff2c$estimate)`, (SE = `r r2(sum_eff2c$se)`, 95% CI [`r r2(sum_eff2c$ci.lb)`, `r r2(sum_eff2c$ci.ub)`], *p* `r psig(sum_eff2c$pval)`), suggesting that there was no difference in looks to the target in response to consonant and tone mispronunciations. The interaction between condition and vowel mispronunciations was also not significant $\beta$ = `r r2(sum_eff2v$estimate)`, (SE = `r r2(sum_eff2v$se)`, 95% CI [`r r2(sum_eff2v$ci.lb)`, `r r2(sum_eff2v$ci.ub)`], *p* `r psig(sum_eff2v$pval)`), suggesting that there was no difference in looks to the target in response to vowel and tone mispronunciations. 

```{r MPtype_cvt_age}
db_MP_type <- subset(db_ET_MP, type_feature == "consonant" | type_feature == "vowel" | type_feature == "tone")

db_MP_type$type_feature <- factor(db_MP_type$type_feature, levels = c("tone", "consonant", "vowel"))

rma_TypeFeaturesMPage <- rma.mv(g_calc, g_var_calc, mods = ~type_feature*age.C, data = db_MP_type, random = ~collapse | short_cite)
 
 

# with condition
db_type <- subset(dat, type_feature == "consonant" | type_feature == "vowel" | type_feature == "tone")

db_type$type_feature <- factor(db_type$type_feature, levels = c("tone", "consonant", "vowel"))

rma_TypeFeaturesMP_Condition <- rma.mv(g_calc, g_var_calc, mods = ~type_feature*condition*age.C, data = db_type, random = ~collapse | short_cite)

sum_eff1 <- coef(summary(rma_TypeFeaturesMP_Condition))[11,]
sum_eff2 <- coef(summary(rma_TypeFeaturesMP_Condition))[12,]

```


We further included an exploratory analysis of the relationship between infant age and the impact of tone mispronunciations in comparison to consonant and vowel mispronunciations. First, for object recognition in response to mispronunciations, when age in addition to mispronunciation location was also included as a moderator, the moderator test was not significant, QM(`r r2(rma_TypeFeaturesMPage$m)`) = `r r2(rma_TypeFeaturesMPage$QM)`, *p* `r psig(rma_TypeFeaturesMPage$QMp)`. This suggests that upon hearing a mispronunciation, infants looks to the target image were not different between tone and vowel or tone and consonant mispronunciations, regardless of their age. We next assessed whether the relationship between mispronunciation type (tone, consonant, vowel) and mispronunciation sensitivity was modulated by age. We merged the two datasets and included condition (correct pronunciation, mispronunciation) as well as age as additional moderators. The moderator test was significant, QM(`r r2(rma_TypeFeaturesMP_Condition$m)`) = `r r2(rma_TypeFeaturesMP_Condition$QM)`, *p* `r psig(rma_TypeFeaturesMP_Condition$QMp)`, but the interactions between condition, age, and both consonant mispronciations ($\beta$ = `r r2(sum_eff1$estimate)`, SE = `r r2(sum_eff1$se)`, 95% CI [`r r2(sum_eff1$ci.lb)`, `r r2(sum_eff1$ci.ub)`], *p* `r psig(sum_eff1$pval)`) and vowel mispronunciations ($\beta$ = `r r2(sum_eff2$estimate)`, SE = `r r2(sum_eff2$se)`, 95% CI [`r r2(sum_eff2$ci.lb)`, `r r2(sum_eff2$ci.ub)`], *p* `r psig(sum_eff2$pval)`) were not significant. Infants' sensitivity to tone mispronunciations compared to consonant or vowel mispronunciations did not differ with age.

[KATIE] WORTH IT TO INCLUDE LANGUAGE FAMILY ANALYSES TOO? I'M THINKING NO





# Discussion

To Summarize:

** Overall Meta-analytic Effect **

  + Accept mispronunciations as labels for targets
  + Sensitive to mispronunciations
  + lack of change over development

** Vocabulary **

  + no relationship?
  + talk about how few studies report it

** Size of Mispronunciation **

  + graded sensitivity to number of features changed in a mispronunciation
  + importance for controlling in experimental design
  + Perhaps a call for more studies to include multiple number of features changed, so that this can be assessed? There was a narrow age where this was actually manipulated.

** Distractor Familiarity **

  + Not really sure, check the results. A key interaction is significant in one model but not the other.
  + Again, ages not matched very well for the two groups here. Similar pattern of results for age subset analysis.

** Phonological overlap between target and distractor **

  + mispronunciation sensitivity was greater when target-distractor pairs shared the same onset phoneme compared to when they shared no phonological overlap
  + this is rather the opposite of what one would expect, right?
  + [Katie: Yeah! Its really strange, so the time course analysis suggestion of yours is a very good one!]
  + Maybe it would be useful to have time course analyses to address this issue further
  + As infants aged, overall recognition (regardless of condition) increased for target-distractor pairs containing onset overlap, whereas overall recognition decreased for target-distractor pairs containing no overlap. 

** Position of mispronunciation **

  + really no impact at all

** Type of mispronunciation **

  + Overall, no difference between consonants and vowels 
  + Consonant mispronunciation sensitivity decreases with age
  + Vowel mispronunciation sensitivity increases with age
  + mispronunciation sensitivity for consonants similar for Germanic and Romance languages
  + Mispronunciation sensitivity for vowels greater for Germanic compared to Romance languages
  + For Germanic infants, increasing age was related to increasing mispronunciation sensitivity for vowel mispronunciations, but decreasing sensitivity for consonant mispronunciations. 
  + For Romance infants, an even greater increase with age in sensitivity to vowel mispronunciations. 
  + For Romance infants, the growth in target looks for consonant mipronunciations increases and surpases that of target looks for correct pronunciations
  + exploratory analyses with tone mispronunciations suggest no great difference in sensitivity when compared to consonant and vowel mispronunciations










When it comes to designing studies, best practices and current standards might not always overlap. Indeed, across a set of previous meta-analyses it was shown that particularly infant research does not adjust sample sizes according to the effect in question (Bergmann et al., in press). A meta-analysis is a first step in improving experiment planning by measuring the underlying effect and its variance, which is directly related to the sample needed to achieve satisfactory power in the null hypothesis significance testing framework. Failing to take effect sizes into account can both yield to underpowered research and to testing too many participants, both consequences are undesirable for a number of reasons that have been discussed in depth elsewhere. We will just briefly mention two that we consider most salient for theory building: Underpowered studies will lead to false negatives more frequently than expected, which in turn results in an unpublished body of literature (citationcitation). Overpowered studies mean that participants were tested unnecessarily, which has substantial ethical consequences particularly when working with infants and other difficult to recruit and test populations. 

From Christina: let's make a note to put sth in the discussion about our curve being surprisingly flat for correctly pronounced words bc people adapt their analysis windows? Bc if you look at Molly's reaction time paper, there is a steep increase.

Discussing the Moderator Analyses
Maybe put them together into the ones that worked out as we predicted and those that didn't? So, here is evidence that supports existing arguments, that doesn't need to be a huge chunk. But then more space devoted to moderator analyses that didn't work out according to predictions.








It should be noted that the majority of consonant mispronunciations were located on the onset phoneme (*n* = `r with(CV_location_info, n_exp_conditions[type_feature == "consonant" & mispron_location == "onset"])`; total consonant conditions, *n* = `r with(CV_info, n_exp_conditions[type_feature == "consonant"])`), while the majority of vowel mispronunciations were located on the medial phoneme (*n* = `r with(CV_location_info, n_exp_conditions[type_feature == "vowel" & mispron_location == "medial"])`; total vowel conditions, *n* = `r with(CV_info, n_exp_conditions[type_feature == "vowel"])`).  In their analysis using TRACE, Mayor and Plunkett (2014) found that the difference between sensitivity to consonant and vowel mispronunciations was due to infants' lexical knowlege consisting of a majority consonant onset words. 

[KATIE] COME BACK TO THIS.


\newpage

# References
```{r create_r-references}
#r_refs(file = "r-MISP_MA_BIB.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
